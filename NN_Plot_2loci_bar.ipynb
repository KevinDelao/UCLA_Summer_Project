{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import shap\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from scipy.stats import sem, t\n",
    "from scipy import mean\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle\n",
    "from random import randrange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate base phenotype values\n",
    "def trait_simulation_twoloci_inter(samples_n,loci_m,var_g,var_e, n_causal_SNPs,b12_event):\n",
    "    #create allele frequencies\n",
    "    f_M = np.random.uniform(0,1,loci_m)\n",
    "    #create G matrix bases on allele frequencies\n",
    "    G = np.random.binomial(n=2,p = f_M, size = (samples_n,loci_m))\n",
    "    #scale or not depending on input, default is True\n",
    "    G = preprocessing.scale(G, axis=0)\n",
    "    #rows are the loci so each person has a row of different loci\n",
    "    individuals = len(G)    \n",
    "    sigma_e = sqrt(var_e)\n",
    "    sigma_b = sqrt(var_g/n_causal_SNPs)\n",
    "    #b_i = loci effect on phenotype\n",
    "    b_1 = np.random.normal(0, sigma_b)\n",
    "    b_2 = np.random.normal(0, sigma_b)\n",
    "    loci =random.sample(range(0, loci_m), 2)\n",
    "    SNP1 = G[:,loci[0]]\n",
    "    SNP2 = G[:,loci[1]]\n",
    "    individuals = len(SNP1)    \n",
    "    #rows are the loci so each person has a row of different loci\n",
    "    Y_n = np.zeros((individuals, 1));\n",
    "    \n",
    "    #depending on b1_event b12 will be different\n",
    "    # if 0 then b12 has no effect\n",
    "    if (b12_event == 0):\n",
    "        b_12 = 0\n",
    "    #if 1 then Random Combined Effect\n",
    "    elif(b12_event == 1):\n",
    "        b_12 = np.random.normal(0, sigma_b)\n",
    "    #if 2 then: 0 < b_12 < b1\n",
    "    elif(b12_event == 2):\n",
    "        b_12 = random.uniform(0, abs(b_1))\n",
    "    #if 3 then: 0 < b_12 < b2\n",
    "    elif(b12_event == 3):\n",
    "        b_12 = random.uniform(0, abs(b_2))\n",
    "    #if 4 then: b_1 + b_2 < b_12\n",
    "    elif(b12_event == 4):\n",
    "        b_12 = random.uniform(abs(b_1) + abs(b_2), 1)\n",
    "    #if 5 then: b_12 < 0\n",
    "    elif(b12_event == 5):\n",
    "        b_12 = random.uniform(-1 * sigma_b, 0)\n",
    "             \n",
    "    #create phenotype vector\n",
    "    for k in range(0, individuals):\n",
    "        #each individual will have a random e_j(noise) value\n",
    "        e_j = np.random.normal(0, sigma_e)\n",
    "        #G_ij will be the jth individual from our SNP for the loci of choice\n",
    "        G_ij1  = SNP1[k]\n",
    "        G_ij2  = SNP2[k]\n",
    "        Y_j = (b_1*G_ij1) + (b_2*G_ij2) + (b_12 * (G_ij1 * G_ij2))+ e_j \n",
    "        Y_n[k] = Y_j \n",
    "    #add Y traits to G matrix\n",
    "    G = np.append(G, Y_n, axis=1)\n",
    "    return G, loci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_NN_train(G):\n",
    "    X = G[:,0:len(G[0])-2]\n",
    "    y = G[:,len(G[0])-1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', input_dim = len(X[0])))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation='relu', input_dim = 32))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.compile(loss='mean_absolute_error', optimizer='rmsprop')\n",
    "    model.fit(x_train, y_train, epochs=50, batch_size=16, verbose = 0)\n",
    "    explainer = shap.DeepExplainer(model, x_train)\n",
    "    shap_values = explainer.shap_values(x_test)\n",
    "    return shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_shap_values(shap_values1):\n",
    "    shap_values1 = np.array(shap_values1)\n",
    "    shap_values2 = np.zeros((len(shap_values1[0]),len(shap_values1[0][0])))\n",
    "    shap_values2[:][:] = shap_values1[0,:,:]\n",
    "#     shap_values2 = np.array(shap_values2)\n",
    "    avg_shap = []\n",
    "    for i in range(0,len(shap_values2[0])):\n",
    "        shap2 = np.mean(abs(shap_values2[:,i]))\n",
    "        avg_shap.append(shap2)\n",
    "    temp1 = np.asarray(avg_shap)\n",
    "    indices = temp1.argsort()[-2:][::-1]\n",
    "    loci1_avgshap,loci2_avgshap = avg_shap[indices[0]],avg_shap[indices[1]]\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_count(actual_loci,predicted_loci):\n",
    "    if (predicted_loci[0] ==actual_loci[0] and predicted_loci[1] ==actual_loci[1]):\n",
    "        return 1\n",
    "    elif (predicted_loci[0] != actual_loci[0] and predicted_loci[1] == actual_loci[1]):\n",
    "        return .5\n",
    "    elif(predicted_loci[0] == actual_loci[0] and predicted_loci[1] != actual_loci[1]):\n",
    "        return .5\n",
    "    else:\n",
    "        return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percents_varg(zeros,halfs,ones):\n",
    "    total = len(zeros)+len(halfs)+len(ones)\n",
    "    perc_0 = len(zeros)/total\n",
    "    perc_0 = perc_0*100\n",
    "    perc_half = len(halfs)/total\n",
    "    perc_half =perc_half*100\n",
    "    perc_1 = len(ones)/total\n",
    "    perc_1 = perc_1*100\n",
    "    list_returned = []\n",
    "    list_returned.append(perc_0)\n",
    "    list_returned.append(perc_half)\n",
    "    list_returned.append(perc_1)\n",
    "    return list_returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "[67.14285714285714, 12.857142857142856, 20.0]"
      ],
      "text/plain": [
       "[67.14285714285714, 12.857142857142856, 20.0]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_g_percents_lists[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "var_g_list =[0,.1,.2,.3,.4,.5,.6,.7,.8,.9]\n",
    "e_list = [0,.1,.2,.3,.4,.5,.6,.7,.8,.9]\n",
    "[float(m) for m in e_list]# #this is a list of list\n",
    "var_g_percents_lists = []\n",
    "acc_list_0 = []\n",
    "b12_event =2\n",
    "n_causal_SNPs =2\n",
    "for i in var_g_list:\n",
    "    num_one = []\n",
    "    num_zero = []\n",
    "    num_half = []\n",
    "    for j in range(0,70):\n",
    "        var_e = e_list[randrange(10)]\n",
    "        G,loci = trait_simulation_twoloci_inter(1000,20,i,var_e, n_causal_SNPs,b12_event)\n",
    "        shap_values2 = shap_NN_train(G)\n",
    "        predicted_loci = mean_shap_values(shap_values2)\n",
    "        num_correct = accuracy_count(loci,predicted_loci)\n",
    "        if(num_correct == 1):\n",
    "            num_one.append(num_correct)\n",
    "        if(num_correct == .5):\n",
    "            num_half.append(num_correct)\n",
    "        if(num_correct == 0):\n",
    "            num_zero.append(num_correct)\n",
    "    var_g_percents_lists.append(percents_varg(num_zero,num_half,num_one))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "[61.42857142857143, 10.0, 28.57142857142857]"
      ],
      "text/plain": [
       "[61.42857142857143, 10.0, 28.57142857142857]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_g_percents_lists[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/kevin/Downloads/NN_two_loci_bar_b12_2', 'wb') as fp:\n",
    "    pickle.dump(var_g_percents_lists, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
