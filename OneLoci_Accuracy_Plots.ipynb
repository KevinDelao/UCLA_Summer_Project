{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import shap\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from scipy.stats import sem, t\n",
    "from scipy import mean\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genotype & Phenotype Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulate Genotype\n",
    "def simulate_genotype(samples_n, loci_m):\n",
    "    f_M = np.random.uniform(0,1,loci_m)\n",
    "    G = np.random.binomial(n=2,p = f_M, size = (samples_n,loci_m))\n",
    "    G = preprocessing.scale(G, axis=0)\n",
    "    \n",
    "    assert(len(G) == samples_n)\n",
    "    assert(len(G[0])== loci_m)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set beta and envi noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide beta_g, e_noise and get G with genotype & Phenotype data\n",
    "def simulate_genotype_and_phenotype_set(samples_n, loci_m,beta_g,e_noise):\n",
    "    G = simulate_genotype(samples_n, loci_m)\n",
    "    loci =random.randint(0,loci_m-1)\n",
    "    SNP = G[:,loci]\n",
    "    individuals = len(SNP)\n",
    "    b_i = beta_g\n",
    "    Y_n = np.zeros((individuals, 1))\n",
    "    for k in range(0, individuals):\n",
    "        #each individual will have a e_j(noise) value\n",
    "        e_j = np.random.normal(0, e_noise)\n",
    "        #G_ij will be the jth individual from our SNP for the loci of choce\n",
    "        G_ij  = SNP[k]\n",
    "        Y_j = b_i*G_ij + e_j\n",
    "        Y_n[k] = Y_j \n",
    "    y_max = np.max(Y_n)\n",
    "    y_max = abs(y_max)\n",
    "    Y_n = np.array(Y_n)\n",
    "    Y_n = Y_n/y_max\n",
    "    Y_n = Y_n.reshape(samples_n,1)\n",
    "    G = np.append(G, Y_n, axis=1)\n",
    "    return G, loci\n",
    "\n",
    "#Provide var_g, var_e and get G with genotype & Phenotype data\n",
    "def simulate_genotype_and_phenotype_var(samples_n, loci_m,var_g,var_e):\n",
    "    G = simulate_genotype(samples_n, loci_m)\n",
    "    loci =random.randint(0,loci_m-1)\n",
    "    SNP = G[:,loci]\n",
    "    individuals = len(SNP)\n",
    "    mean = 0 \n",
    "    sigma_b = sqrt(var_g)\n",
    "    sigma_e = sqrt(var_e)\n",
    "    b_i = np.random.normal(0, sigma_b)\n",
    "    Y_n = np.zeros((individuals, 1))\n",
    "    for k in range(0, individuals):\n",
    "        #each individual will have a random e_j(noise) value\n",
    "        e_j = np.random.normal(0, sigma_e)\n",
    "        #G_ij will be the jth individual from our SNP for the loci of choce\n",
    "        G_ij  = SNP[k]\n",
    "        Y_j = b_i*G_ij + e_j\n",
    "        Y_n[k] = Y_j\n",
    "    y_max = np.max(Y_n)\n",
    "    y_max = abs(y_max)\n",
    "#     Y_n = np.array(Y_n)\n",
    "    Y_n = Y_n/y_max\n",
    "#     Y_n = Y_n.reshape(samples_n,1)\n",
    "    G = np.append(G, Y_n, axis=1)\n",
    "    return G, loci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression & SHAP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_RFR_tree_train(G):\n",
    "    X = G[:,0:len(G[0])-1]\n",
    "    y = G[:,len(G[0])-1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "#     forReg = RandomForestRegressor(max_depth=10, random_state=0, n_estimators=50)\n",
    "#     forReg.fit(x_train, y_train)\n",
    "#     shap_values = shap.TreeExplainer(forReg).shap_values(x_train)\n",
    "    linReg = LinearRegression() \n",
    "    linReg.fit(x_train, y_train) \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    explainer = shap.KernelExplainer(linReg.predict, shap.sample(x_train,100))\n",
    "    shap_values = explainer.shap_values(x_test)\n",
    "    return shap_values, x_train\n",
    "\n",
    "def shap_feature_plot_RFR(shap_values, x_train):\n",
    "    shap.summary_plot(shap_values, x_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def shap_RFR_tree_train(G):\n",
    "#     X = G[:,0:len(G[0])-1]\n",
    "#     y = G[:,len(G[0])-1]\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(256, activation='softmax', input_dim = len(X[0])))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Dense(1, activation='softmax', input_dim = 256))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.compile(loss='mean_absolute_error', optimizer='SGD')\n",
    "#     model.fit(x_train, y_train, epochs=10, batch_size=10, verbose = 0)\n",
    "#     explainer = shap.DeepExplainer(model, x_train)\n",
    "#     shap_values = explainer.shap_values(x_test)\n",
    "#     return shap_values, x_train\n",
    "\n",
    "# def shap_feature_plot_RFR(shap_values, x_train):\n",
    "#     shap.summary_plot(shap_values, x_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for RFR\n",
    "def mean_shap_values(shap_values):\n",
    "    \n",
    "    shap_values = np.array(shap_values)\n",
    "    avg_shap = []\n",
    "    for i in range(0,len(shap_values[0])):\n",
    "        shap2 = np.mean(abs(shap_values[:,i]))\n",
    "        avg_shap.append(shap2)\n",
    "    return avg_shap\n",
    "##for NN\n",
    "# def mean_shap_values(shap_values):\n",
    "#     shap_values = np.array(shap_values)\n",
    "#     shap_values2 = np.zeros((len(shap_values[0]),len(shap_values[0][0])))\n",
    "#     shap_values2[:][:] = shap_values[0,:,:]\n",
    "# #     shap_values2 = np.array(shap_values2)\n",
    "#     avg_shap = []\n",
    "#     for i in range(0,len(shap_values2[0])):\n",
    "#         shap2 = np.mean(abs(shap_values2[:,i]))\n",
    "#         avg_shap.append(shap2)\n",
    "#     return avg_shap   \n",
    "\n",
    "def max_mean_feature(shap_values):\n",
    "    '''\n",
    "    mean_shap = mean_shap_values(shap_values)\n",
    "    return mean_shap.index(max(mean_shap)), mean_shap[mean_shap.index(max(mean_shap))]\n",
    "    '''\n",
    "    avg_shap = mean_shap_values(shap_values)\n",
    "    temp1 = np.asarray(avg_shap)\n",
    "    indices = temp1.argsort()[-2:][::-1]\n",
    "    loci1,loci2 = avg_shap[indices[0]],avg_shap[indices[1]]\n",
    "    return indices[0], loci1\n",
    "\n",
    "#TEST BEFORE USING\n",
    "def max_mean_features(shap_values, no_features = 2):\n",
    "    avg_shap = mean_shap_values(shap_values)\n",
    "    assert(no_features <= len(avg_shap)), 'max_mean_features(), more features requested then in list'\n",
    "    temp1 = np.asarray(avg_shap)\n",
    "    indices = temp1.argsort()[-no_features:][::-1]\n",
    "    #loci1,loci2 = avg_shap[indices[0]],avg_shap[indices[1]]\n",
    "    return indices\n",
    "\n",
    "#G, loci = simulate_genotype_and_phenotype_set(10, 5,0.8,0.2)\n",
    "#shap_values, x_train = shap_RFR_tree_train(G)\n",
    "#shap_feature_plot_RFR(shap_values, x_train)\n",
    "#means = max_mean_feature(shap_values)\n",
    "#means\n",
    "#shap_acc_RFR_set(100, 10, 0.9, 0, 100, confidence = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_acc_RFR_set(samples_n, loci_m, beta_g, e_noise, number_trials, confidence = 0.95):\n",
    "    shap_values_SNP = []\n",
    "    counter = 0\n",
    "    while counter != number_trials:\n",
    "        G, loci = simulate_genotype_and_phenotype_set(samples_n, loci_m,beta_g,e_noise)\n",
    "        shap_values_holder, x_train = shap_RFR_tree_train(G)\n",
    "        max_holder = max_mean_feature(shap_values_holder)\n",
    "        if max_holder[0] == loci:\n",
    "            shap_values_SNP.append(1)\n",
    "        else:\n",
    "            shap_values_SNP.append(0)\n",
    "        counter += 1\n",
    "    \n",
    "    percent = sum(shap_values_SNP) / len(shap_values_SNP) * 100\n",
    "    \n",
    "    n = len(shap_values_SNP)\n",
    "    m = mean(shap_values_SNP)\n",
    "    std_err = sem(shap_values_SNP)\n",
    "    confidence_int = std_err * t.ppf((1 + confidence) / 2, n - 1)\n",
    "    \n",
    "    return percent, confidence_int\n",
    "    \n",
    "\n",
    "def shap_acc_RFR_var(samples_n, loci_m, var_g, var_e, number_trials):\n",
    "    shap_values_SNP = []\n",
    "    counter = 0\n",
    "    while counter != number_trials:\n",
    "        G, loci = simulate_genotype_and_phenotype_var(samples_n,loci_m, var_g , var_e)\n",
    "        shap_values_holder, x_train = shap_RFR_tree_train(G)\n",
    "        max_holder = max_mean_feature(shap_values_holder)\n",
    "        if max_holder[0] == loci:\n",
    "            shap_values_SNP.append(1)\n",
    "        else:\n",
    "            shap_values_SNP.append(0)\n",
    "        counter += 1\n",
    "    percent = sum(shap_values_SNP) / len(shap_values_SNP) * 100\n",
    "    confidence_int = 1\n",
    "    return percent, confidence_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples_n = 100\n",
    "#loci_m = 10\n",
    "#number_trials = 100\n",
    "#beta_g, e_noise = 0.9, 0.2\n",
    "#percent, confidence_int = shap_acc_RFR_set(samples_n, loci_m, beta_g, e_noise , number_trials, confidence = 0.95)\n",
    "#print(percent)\n",
    "#print(confidence_int)\n",
    "    \n",
    "#pickle.dump( [percent, beta_g, e_noise, confidence_int], open( \"save.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#favorite_color = pickle.load( open( \"save.p\", \"rb\" ) )\n",
    "#print(favorite_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Line Plots\n",
    "def plot_shap_values_RFR_line_single(samples_n, loci_m, range_values, e_val, number_trials, data_type = 'set'):\n",
    "    \n",
    "    increment = 1/range_values\n",
    "    holderg = 0\n",
    "    g_vals = [0]\n",
    "    \n",
    "    for x in range(1, range_values):\n",
    "        g_vals.append(holderg + increment)\n",
    "        holderg = holderg + increment\n",
    "    \n",
    "    shap_values_SNP = []\n",
    "    \n",
    "    if data_type == 'set':\n",
    "        for x in range(0,range_values):\n",
    "            percent, confidence_int = shap_acc_RFR_set(samples_n, loci_m, g_vals[x], e_val, number_trials)\n",
    "            shap_values_SNP.append(percent)\n",
    "    elif data_type == 'var':\n",
    "        for x in range(0,range_values):\n",
    "            percent, confidence_int = shap_acc_RFR_var(samples_n, loci_m, g_vals[x], e_val, number_trials)\n",
    "            shap_values_SNP.append(percent)\n",
    "\n",
    "            \n",
    "    plt.plot(g_vals, shap_values_SNP) \n",
    "    \n",
    "    if data_type == 'set':\n",
    "        plt.xlabel('Value of Genetic Effect')\n",
    "        plt.ylabel('Percent accuracy of feature selection')\n",
    "        plt.title('Effect of Genetic Effect on SHAP Accuracy in Feature Selection') \n",
    "    elif data_type == 'var':\n",
    "        plt.xlabel('Variance of Genetic Effect')\n",
    "        plt.ylabel('Percent accuracy of feature selection')\n",
    "        plt.title('Effect of Variance Genetic Effect on SHAP Accuracy in Feature Selection') \n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples_n = 100\n",
    "# loci_m = 10\n",
    "# range_values = 10\n",
    "# number_trials = 100\n",
    "# plot_shap_values_RFR_line_single(samples_n, loci_m, range_values, 0.3, number_trials, data_type = 'set')\n",
    "# #plot_shap_values_RFR_line_single(samples_n, loci_m, range_values, 0.5, number_trials, data_type = 'set')\n",
    "# #plot_shap_values_RFR_line_single(samples_n, loci_m, range_values, 0.7, number_trials, data_type = 'set')\n",
    "# #plot_shap_values_RFR_line_single(samples_n, loci_m, range_values, 0.9, number_trials, data_type = 'set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples_n = 100\n",
    "#loci_m = 10\n",
    "#range_values = 10\n",
    "#number_trials = 100\n",
    "#plot_shap_values_RFR_line_single(samples_n, loci_m, range_values, 0.3, number_trials, data_type = 'set')\n",
    "#plot_shap_values_RFR_line_single(samples_n, loci_m, range_values, 0.5, number_trials, data_type = 'set')\n",
    "#plot_shap_values_RFR_line_single(samples_n, loci_m, range_values, 0.7, number_trials, data_type = 'set')\n",
    "#plot_shap_values_RFR_line_single(samples_n, loci_m, range_values, 0.9, number_trials, data_type = 'set')\n",
    "\n",
    "#plot_shap_values_RFR_line_single(samples_n, loci_m, range_values, 0.3, number_trials, data_type = 'var')\n",
    "#plot_shap_values_RFR_line_single(samples_n, loci_m, range_values, 0.5, number_trials, data_type = 'var')\n",
    "#plot_shap_values_RFR_line_single(samples_n, loci_m, range_values, 0.7, number_trials, data_type = 'var')\n",
    "#plot_shap_values_RFR_line_single(samples_n, loci_m, range_values, 0.9, number_trials, data_type = 'var')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Line Plots\n",
    "def plot_shap_values_RFR_line_multiple(samples_n, loci_m, range_values_g, range_values_e, number_trials, name = 'nameme', data_type = 'set'):\n",
    "    \n",
    "    increment_g = 1/range_values_g\n",
    "    increment_e = 1/range_values_e\n",
    "    holderg = 0\n",
    "    holdere = 0\n",
    "    g_vals = [0]\n",
    "    e_vals = [0]\n",
    "    \n",
    "    for x in range(1, range_values_g):\n",
    "        g_vals.append(holderg + increment_g)\n",
    "        holderg = holderg + increment_g\n",
    "        \n",
    "    for x in range(1, range_values_e):\n",
    "        e_vals.append(holdere + increment_e)\n",
    "        holdere = holdere + increment_e\n",
    "    \n",
    "    \n",
    "    shap_values_SNP = []\n",
    "    \n",
    "    if data_type == 'set':\n",
    "        for y in range(0, range_values_e):\n",
    "            shap_values_SNP_holder = []\n",
    "            for x in range(0,range_values_g):\n",
    "                percent, confidence_int = shap_acc_RFR_set(samples_n, loci_m, g_vals[x], e_vals[y], number_trials)\n",
    "                shap_values_SNP_holder.append(percent)\n",
    "            shap_values_SNP.append(shap_values_SNP_holder)\n",
    "    elif data_type == 'var':\n",
    "        for y in range(0, range_values_e):\n",
    "            shap_values_SNP_holder = []\n",
    "            for x in range(0,range_values_g):\n",
    "                percent, confidence_int = shap_acc_RFR_var(samples_n, loci_m, g_vals[x], e_vals[y], number_trials)\n",
    "                shap_values_SNP_holder.append(percent)\n",
    "            shap_values_SNP.append(shap_values_SNP_holder)\n",
    "\n",
    "    for x in range(0, len(shap_values_SNP)):\n",
    "        e_vals[x] = str(round(e_vals[x], 2))\n",
    "        plt.plot(g_vals, shap_values_SNP[x], label = e_vals[x]) \n",
    "    \n",
    "    if data_type == 'set':\n",
    "        plt.xlabel('Value of Genetic Effect')\n",
    "        plt.ylabel('Percent accuracy of feature selection')\n",
    "        plt.ylim([0,100])\n",
    "\n",
    "        plt.title('Effect of Genetic Effect on SHAP Accuracy in Feature Selection') \n",
    "    elif data_type == 'var':\n",
    "        plt.xlabel('Variance of Genetic Effect')\n",
    "        plt.ylabel('Percent accuracy of feature selection')\n",
    "        plt.ylim([0,100])\n",
    "\n",
    "        plt.title('Effect of Variance Genetic Effect on SHAP Accuracy in Feature Selection') \n",
    "        \n",
    "    plt.legend(title = 'Environmental Noise')\n",
    "    plt.savefig(name)\n",
    "    return g_vals,shap_values_SNP,e_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples_n = 1000\n",
    "loci_m = 20\n",
    "range_values_g = 10\n",
    "range_values_e = 5\n",
    "number_trials = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-dd542d2583aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mg_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshap_values_SNP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_shap_values_RFR_line_multiple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloci_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange_values_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange_values_e\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_trials\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'NN_One_Loci_fixed_var_new'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'var'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-70-b24aba1c3afe>\u001b[0m in \u001b[0;36mplot_shap_values_RFR_line_multiple\u001b[1;34m(samples_n, loci_m, range_values_g, range_values_e, number_trials, name, data_type)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mshap_values_SNP_holder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrange_values_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                 \u001b[0mpercent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfidence_int\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshap_acc_RFR_var\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloci_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_vals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_vals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m                 \u001b[0mshap_values_SNP_holder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpercent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mshap_values_SNP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshap_values_SNP_holder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-38b7a8830540>\u001b[0m in \u001b[0;36mshap_acc_RFR_var\u001b[1;34m(samples_n, loci_m, var_g, var_e, number_trials)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mcounter\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnumber_trials\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloci\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimulate_genotype_and_phenotype_var\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples_n\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloci_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_g\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mvar_e\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mshap_values_holder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshap_RFR_tree_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mmax_holder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_mean_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshap_values_holder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmax_holder\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mloci\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-73-ef9166bd5ea1>\u001b[0m in \u001b[0;36mshap_RFR_tree_train\u001b[1;34m(G)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#     shap_values = shap.TreeExplainer(forReg).shap_values(x_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mlinReg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mlinReg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mexplainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKernelExplainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinReg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0m\u001b[0;32m    506\u001b[0m                                    y_numeric=True, multi_output=True)\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    803\u001b[0m                     estimator=estimator)\n\u001b[0;32m    804\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n\u001b[0m\u001b[0;32m    806\u001b[0m                         ensure_2d=False, dtype=None)\n\u001b[0;32m    807\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    646\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     95\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     96\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     98\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "g_vals,shap_values_SNP,e_vals = plot_shap_values_RFR_line_multiple(samples_n, loci_m, range_values_g, range_values_e, number_trials,'NN_One_Loci_fixed_var_new', data_type = 'var' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN_one_lociList = []\n",
    "# NN_one_lociList.append(g_vals)\n",
    "# NN_one_lociList.append(shap_values_SNP)\n",
    "# NN_one_lociList.append(e_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import pickle\n",
    "# with open('/Users/kevin/Downloads/RFR_one_lociList_var', 'wb') as fp:\n",
    "#     pickle.dump(NN_one_lociList, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in range(0, len(shap_values_SNP)):\n",
    "# #     e_vals[x] = str(round(e_vals[x], 2))\n",
    "#     plt.plot(g_vals, shap_values_SNP[x], label = e_vals[x]) \n",
    "    \n",
    "\n",
    "# plt.xlabel('Variance of Genetic Effect')\n",
    "# plt.ylabel('Percent accuracy of feature selection')\n",
    "# plt.ylim([0,100])\n",
    "# plt.title('Effect of Variance Genetic Effect on SHAP Accuracy')     \n",
    "# plt.legend(title = 'Environmental Noise')\n",
    "# plt.savefig('RFR_One_Loci_fixed_var')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples_n = 1000\n",
    "# loci_m = 20\n",
    "# range_values_g = 10\n",
    "# range_values_e = 5\n",
    "# number_trials = 100\n",
    "# # plot_shap_values_RFR_line_multiple(samples_n, loci_m, range_values_g, range_values_e, \n",
    "# # number_trials, 'RFR_set_10000', data_type = 'set')\n",
    "# plot_shap_values_RFR_line_multiple(samples_n, loci_m, range_values_g, range_values_e, \n",
    "#                                    number_trials,'RFR_var_1000', data_type = 'var' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Bar Plots\n",
    "# def plot_shap_values_RFR_bar(samples_n, loci_m, range_values, e_val, number_trials, data_type = 'set'):\n",
    "    \n",
    "#     increment = 1/range_values\n",
    "#     holderg = 0\n",
    "#     g_vals = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    \n",
    "#     shap_values_SNP = []\n",
    "#     error = []\n",
    "#     if data_type == 'set':\n",
    "#         for x in range(0,range_values):\n",
    "#             percent, confidence_int = shap_acc_RFR_set(samples_n, loci_m, g_vals[x], e_val, number_trials)\n",
    "#             shap_values_SNP.append(percent)\n",
    "#             error.append(confidence_int)\n",
    "#             print(confidence_int)\n",
    "#     elif data_type == 'var':\n",
    "#         for x in range(0,range_values):\n",
    "#             percent, confidence_int = shap_acc_RFR_var(samples_n, loci_m, g_vals[x], e_val, number_trials)\n",
    "#             shap_values_SNP.append(percent)\n",
    "#             error.append(confidence_int)\n",
    "\n",
    "#     # The x position of bars\n",
    "#     barWidth = 0.7\n",
    "#     r1 = np.arange(len(shap_values_SNP))\n",
    "#     r2 = [x + barWidth for x in r1]\n",
    "    \n",
    "#     bars = g_vals\n",
    "#     x_pos = np.arange(len(bars))\n",
    " \n",
    "#     # Create blue bars\n",
    "#     plt.bar(r1, shap_values_SNP, width = barWidth, color = 'yellow', edgecolor = 'black', yerr=error, capsize=7)\n",
    "\n",
    "#     # general layout\n",
    "#     plt.xticks(x_pos, g_vals)\n",
    "#     plt.ylabel('Percent accuracy of feature selection')\n",
    "\n",
    "#     plt.plot(g_vals, shap_values_SNP) \n",
    "    \n",
    " \n",
    "#     if data_type == 'set':\n",
    "#         plt.xlabel('Value of Genetic Effect')\n",
    "#         plt.title('Effect of Genetic Effect on SHAP Accuracy in Feature Selection') \n",
    "#     elif data_type == 'var':\n",
    "#         plt.xlabel('Variance of Genetic Effect')\n",
    "#         plt.title('Effect of Variance Genetic Effect on SHAP Accuracy in Feature Selection') \n",
    "        \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples_n = 100\n",
    "# loci_m = 10\n",
    "# number_trials = 100\n",
    "# beta_g, e_noise = 0.9, 0.2\n",
    "# percent, confidence_int = shap_acc_RFR_set(samples_n, loci_m, beta_g, e_noise , number_trials, confidence = 0.95)\n",
    "# print(percent)\n",
    "# print(confidence_int)\n",
    "    \n",
    "# pickle.dump( [percent, beta_g, e_noise, confidence_int], open( \"save.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
