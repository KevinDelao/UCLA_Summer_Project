{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import shap\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from scipy.stats import sem, t\n",
    "from scipy import mean\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulate Genotype\n",
    "def simulate_genotype(samples_n, loci_m):\n",
    "    f_M = np.random.uniform(0,1,loci_m)\n",
    "    G = np.random.binomial(n=2,p = f_M, size = (samples_n,loci_m))\n",
    "    G = preprocessing.scale(G, axis=0)\n",
    "    \n",
    "    assert(len(G) == samples_n)\n",
    "    assert(len(G[0])== loci_m)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_genotype_and_phenotype(samples_n, loci_m,beta_g,e_noise):\n",
    "    G = simulate_genotype(samples_n, loci_m)\n",
    "    loci =random.randint(0,loci_m-1)\n",
    "    SNP = G[:,loci]\n",
    "    individuals = len(SNP)\n",
    "    b_i = beta_g\n",
    "    Y_n = np.zeros((individuals, 1))\n",
    "    for k in range(0, individuals):\n",
    "        #each individual will have a e_j(noise) value\n",
    "        e_j = np.random.normal(0, e_noise)\n",
    "        #G_ij will be the jth individual from our SNP for the loci of choce\n",
    "        G_ij  = SNP[k]\n",
    "        Y_j = b_i*G_ij + e_j\n",
    "        Y_n[k] = Y_j \n",
    "    y_max = np.max(Y_n)\n",
    "    y_max = abs(y_max)\n",
    "    Y_n = np.array(Y_n)\n",
    "    Y_n = Y_n/y_max\n",
    "    Y_n = Y_n.reshape(samples_n,1)\n",
    "    G = np.append(G, Y_n, axis=1)\n",
    "    return G, loci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_LR_tree_train(G):\n",
    "    X = G[:,0:len(G[0])-1]\n",
    "    y = G[:,len(G[0])-1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    linReg = LinearRegression() \n",
    "    np.isnan(x_train)\n",
    "    np.where(np.isnan(x_train))\n",
    "    x_train = np.nan_to_num(x_train)\n",
    "    y_train = np.nan_to_num(y_train)\n",
    "    linReg.fit(x_train, y_train) \n",
    "    explainer = shap.KernelExplainer(linReg.predict, shap.kmeans(x_train,100))\n",
    "    shap_values = explainer.shap_values(x_train)\n",
    "    return shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def shap_LR_tree_train(G):\n",
    "#     X = G[:,0:len(G[0])-1]\n",
    "#     y = G[:,len(G[0])-1]\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "#     forReg = RandomForestRegressor(max_depth=20, min_samples_split =5,min_samples_leaf=4,random_state=0, n_estimators=1000)\n",
    "#     np.isnan(x_train)\n",
    "#     np.where(np.isnan(x_train))\n",
    "#     x_train = np.nan_to_num(x_train)\n",
    "#     y_train = np.nan_to_num(y_train)\n",
    "\n",
    "#     forReg.fit(x_train, y_train)\n",
    "#     shap_values = shap.TreeExplainer(forReg).shap_values(x_train)\n",
    "#     return shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def shap_LR_tree_train(G):\n",
    "#     X = G[:,0:len(G[0])-1]\n",
    "#     y = G[:,len(G[0])-1]\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(256, activation='relu', input_dim = len(X[0])))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Dense(1, activation='relu', input_dim = 256))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "#     np.isnan(x_train)\n",
    "#     np.where(np.isnan(x_train))\n",
    "#     x_train = np.nan_to_num(x_train)\n",
    "#     y_train = np.nan_to_num(y_train)\n",
    "#     model.fit(x_train, y_train, epochs=10, batch_size=10, verbose = 0)\n",
    "#     explainer = shap.DeepExplainer(model, x_train)\n",
    "#     shap_values = explainer.shap_values(x_train)\n",
    "#     return shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FOR NN\n",
    "# def mean_shap_values(shap_values):\n",
    "#     shap_values = np.array(shap_values)\n",
    "#     shap_values2 = np.zeros((len(shap_values[0]),len(shap_values[0][0])))\n",
    "#     shap_values2[:][:] = shap_values[0,:,:]\n",
    "# #     shap_values2 = np.array(shap_values2)\n",
    "#     avg_shap = []\n",
    "#     for i in range(0,len(shap_values2[0])):\n",
    "#         shap2 = np.mean(abs(shap_values2[:,i]))\n",
    "#         avg_shap.append(shap2)\n",
    "#     return avg_shap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for LR\n",
    "def mean_shap_values(shap_values):\n",
    "    shap_values = np.array(shap_values)\n",
    "    avg_shap = []\n",
    "    for i in range(0,len(shap_values[0])):\n",
    "        shap2 = np.mean(abs(shap_values[:,i]))\n",
    "        avg_shap.append(shap2)\n",
    "#     return avg_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_mean_feature(shap_values):\n",
    "    avg_shap = mean_shap_values(shap_values)\n",
    "    temp1 = np.asarray(avg_shap)\n",
    "    temp2 = temp1\n",
    "    indices = temp1.argsort()[-2:][::-1]\n",
    "    avg_shap_loci1,avg_shap_loci2 = avg_shap[indices[0]],avg_shap[indices[1]]\n",
    "    return indices[0], avg_shap_loci1,temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_FP(shap_vals,casual_loci_index,threshold):\n",
    "    for i in range (0, len(shap_vals)):\n",
    "        if(i != casual_loci_index and shap_vals[i] >= threshold):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_sum(shap_vals,casual_loci_index,threshold):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    for i in range (0, len(shap_vals)):\n",
    "        #TP\n",
    "        if(i == casual_loci_index and shap_vals[i] >= threshold):\n",
    "            TP = TP+1\n",
    "        #FN\n",
    "        elif(i == casual_loci_index and shap_vals[i] < threshold):\n",
    "            FN =  FN+1\n",
    "        #TN\n",
    "        elif(i != casual_loci_index and shap_vals[i] < threshold):\n",
    "            TN = TN+1\n",
    "        #FP\n",
    "        elif(i != casual_loci_index and shap_vals[i] >= threshold):\n",
    "            FP = FP+1\n",
    "        else:\n",
    "            a = 1\n",
    "\n",
    "    return TP,FP,TN,FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open ('/Users/kevin/Downloads/metrics_SHAP_FPR_LR', 'rb') as fp:\n",
    "#     FPR_List_Total = pickle.load(fp)\n",
    "# with open ('/Users/kevin/Downloads/metrics_SHAP_TPR_LR', 'rb') as fp:\n",
    "#     TPR_List_Total = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee8d5939ee064374af3cc177d4f165e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=280.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-991c35aae559>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mloci_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloci\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mshap_values_holder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshap_LR_tree_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mmax_holder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_mean_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshap_values_holder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mavg_shap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_holder\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mavg_SHAP_List\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_shap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-8ba5b6d54a63>\u001b[0m in \u001b[0;36mmax_mean_feature\u001b[1;34m(shap_values)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtemp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mavg_shap_loci1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mavg_shap_loci2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg_shap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mavg_shap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg_shap_loci1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "FPR_List_Total = []\n",
    "TPR_List_Total = []\n",
    "threshold_list = np.linspace(0,1,200)\n",
    "var_g_list = [0.1, 0.2,0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "var_e_list  =[0,.2,.4,.6,.8]\n",
    "samples = 400\n",
    "features = 20\n",
    "# metric_lists_total =  []\n",
    "for var_e in var_e_list:\n",
    "    FPR_List = []\n",
    "    TPR_List = []\n",
    "    avg_SHAP_List = []\n",
    "    loci_list = []\n",
    "    for var_g in var_g_list:\n",
    "        G, loci = simulate_genotype_and_phenotype(samples,features, var_g , var_e)\n",
    "        loci_list.append(loci)\n",
    "        shap_values_holder = shap_LR_tree_train(G)\n",
    "        max_holder = max_mean_feature(shap_values_holder)\n",
    "        avg_shap = max_holder[2]\n",
    "        avg_SHAP_List.append(avg_shap)\n",
    "    for threshold in threshold_list:\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "        for i in range(0,9):\n",
    "            avg_shap = avg_SHAP_List[i]   \n",
    "            loci_temp = loci_list[i]\n",
    "            metrics = metrics_sum(avg_shap,loci_temp,threshold)\n",
    "            TP = TP+metrics[0]\n",
    "            FP = FP+metrics[1]\n",
    "            TN = TN+metrics[2]\n",
    "            FN = FN+metrics[3]\n",
    "        TPR = TP/(TP+FN)\n",
    "        FPR = FP/(FP+TN)\n",
    "        FPR_List.append(FPR)\n",
    "        TPR_List.append(TPR)\n",
    "    FPR_List_Total.append(FPR_List)\n",
    "    TPR_List_Total.append(TPR_List) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open ('/Users/kevin/Desktop/UCLA_BIG_Code/Code_Data/LR_metrics_toplot/metrics_LR_varg_1', 'rb') as fp:\n",
    "#     corr2list = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/kevin/Downloads/metrics_SHAP_FPR_LR', 'wb') as fp:\n",
    "#     pickle.dump(FPR_List_Total, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/kevin/Downloads/metrics_SHAP_TPR_LR', 'wb') as fp:\n",
    "#     pickle.dump(TPR_List_Total, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# Roc Curve:\n",
    "plt.plot(FPR_List_Total[0], TPR_List_Total[0], color='red', lw=2,\n",
    "         label='var_e = 0')\n",
    "plt.plot(FPR_List_Total[1], TPR_List_Total[1], color='green', lw=2,\n",
    "         label='var_e = .2')\n",
    "plt.plot(FPR_List_Total[2], TPR_List_Total[2], color='purple', lw=2,\n",
    "         label='var_e = .4')\n",
    "plt.plot(FPR_List_Total[3], TPR_List_Total[3], color='orange', lw=2, \n",
    "         label='var_e = .6')\n",
    "plt.plot(FPR_List_Total[4], TPR_List_Total[4], color='cyan', lw=2,\n",
    "         label='var_e = .8')\n",
    "#Random Guess line:\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=1, linestyle='--')\n",
    "\n",
    "# Defining The Range of X-Axis and Y-Axis:\n",
    "plt.xlim([0.0, 1.01])\n",
    "plt.ylim([0.0, 1.01])\n",
    "\n",
    "# Labels, Title, Legend:\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('SHAP Values Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('LR_1000_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
