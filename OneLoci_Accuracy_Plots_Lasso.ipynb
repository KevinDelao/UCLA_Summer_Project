{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import shap\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import linear_model\n",
    "from scipy.stats import sem, t\n",
    "from scipy import mean\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genotype & Phenotype Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulate Genotype\n",
    "def simulate_genotype(samples_n, loci_m):\n",
    "    f_M = np.random.uniform(0,1,loci_m)\n",
    "    G = np.random.binomial(n=2,p = f_M, size = (samples_n,loci_m))\n",
    "    G = preprocessing.scale(G, axis=0)\n",
    "    \n",
    "    assert(len(G) == samples_n)\n",
    "    assert(len(G[0])== loci_m)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set beta and envi noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_genotype_and_phenotype_set(samples_n, loci_m,beta_g,e_noise):\n",
    "    G = simulate_genotype(samples_n, loci_m)\n",
    "    loci =random.randint(0,loci_m-1)\n",
    "    SNP = G[:,loci]\n",
    "    individuals = len(SNP)\n",
    "    b_i = beta_g\n",
    "    Y_n = np.zeros((individuals, 1))\n",
    "    for k in range(0, individuals):\n",
    "        #each individual will have a e_j(noise) value\n",
    "        e_j = np.random.normal(0, e_noise)\n",
    "        #G_ij will be the jth individual from our SNP for the loci of choce\n",
    "        G_ij  = SNP[k]\n",
    "        Y_j = b_i*G_ij + e_j\n",
    "        Y_n[k] = Y_j \n",
    "    G = np.append(G, Y_n, axis=1)\n",
    "    return G, loci\n",
    "\n",
    "#Provide var_g, var_e and get G with genotype & Phenotype data\n",
    "def simulate_genotype_and_phenotype_var(samples_n, loci_m,var_g,var_e):\n",
    "    G = simulate_genotype(samples_n, loci_m)\n",
    "    loci =random.randint(0,loci_m-1)\n",
    "    SNP = G[:,loci]\n",
    "    individuals = len(SNP)\n",
    "    mean = 0 \n",
    "    sigma_b = sqrt(var_g)\n",
    "    sigma_e = sqrt(var_e)\n",
    "    b_i = np.random.normal(0, sigma_b)\n",
    "    Y_n = np.zeros((individuals, 1))\n",
    "    for k in range(0, individuals):\n",
    "        #each individual will have a random e_j(noise) value\n",
    "        e_j = np.random.normal(0, sigma_e)\n",
    "        #G_ij will be the jth individual from our SNP for the loci of choce\n",
    "        G_ij  = SNP[k]\n",
    "        Y_j = b_i*G_ij + e_j\n",
    "        Y_n[k] = Y_j \n",
    "    G = np.append(G, Y_n, axis=1)\n",
    "    return G, loci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression & SHAP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_RFR_tree_train(G):\n",
    "    X = G[:,0:len(G[0])-1]\n",
    "    y = G[:,len(G[0])-1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    lassoReg = linear_model.Lasso(alpha=0.1)\n",
    "    lassoReg.fit(x_train, y_train)\n",
    "    explainer = shap.KernelExplainer(lassoReg.predict, shap.kmeans(x_train,100))\n",
    "    shap_values = explainer.shap_values(x_test)\n",
    "    return shap_values, x_train\n",
    "\n",
    "def shap_feature_plot_RFR(shap_values, x_train):\n",
    "    shap.summary_plot(shap_values, x_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for RFR\n",
    "def mean_shap_values(shap_values):\n",
    "    \n",
    "    shap_values = np.array(shap_values)\n",
    "    avg_shap = []\n",
    "    for i in range(0,len(shap_values[0])):\n",
    "        shap2 = np.mean(abs(shap_values[:,i]))\n",
    "        avg_shap.append(shap2)\n",
    "    return avg_shap\n",
    "#for NN\n",
    "# def mean_shap_values(shap_values):\n",
    "#     shap_values = np.array(shap_values)\n",
    "#     shap_values2 = np.zeros((len(shap_values[0]),len(shap_values[0][0])))\n",
    "#     shap_values2[:][:] = shap_values[0,:,:]\n",
    "# #     shap_values2 = np.array(shap_values2)\n",
    "#     avg_shap = []\n",
    "#     for i in range(0,len(shap_values2[0])):\n",
    "#         shap2 = np.mean(abs(shap_values2[:,i]))\n",
    "#         avg_shap.append(shap2)\n",
    "#     return avg_shap   \n",
    "\n",
    "def max_mean_feature(shap_values):\n",
    "    '''\n",
    "    mean_shap = mean_shap_values(shap_values)\n",
    "    return mean_shap.index(max(mean_shap)), mean_shap[mean_shap.index(max(mean_shap))]\n",
    "    '''\n",
    "    avg_shap = mean_shap_values(shap_values)\n",
    "    temp1 = np.asarray(avg_shap)\n",
    "    indices = temp1.argsort()[-2:][::-1]\n",
    "    loci1,loci2 = avg_shap[indices[0]],avg_shap[indices[1]]\n",
    "    return indices[0], loci1\n",
    "\n",
    "#TEST BEFORE USING\n",
    "def max_mean_features(shap_values, no_features = 2):\n",
    "    avg_shap = mean_shap_values(shap_values)\n",
    "    assert(no_features <= len(avg_shap)), 'max_mean_features(), more features requested then in list'\n",
    "    temp1 = np.asarray(avg_shap)\n",
    "    indices = temp1.argsort()[-no_features:][::-1]\n",
    "    #loci1,loci2 = avg_shap[indices[0]],avg_shap[indices[1]]\n",
    "    return indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_acc_RFR_set(samples_n, loci_m, beta_g, e_noise, number_trials, confidence = 0.95):\n",
    "    shap_values_SNP = []\n",
    "    counter = 0\n",
    "    while counter != number_trials:\n",
    "        G, loci = simulate_genotype_and_phenotype_set(samples_n, loci_m,beta_g,e_noise)\n",
    "        shap_values_holder, x_train = shap_RFR_tree_train(G)\n",
    "        max_holder = max_mean_feature(shap_values_holder)\n",
    "        if max_holder[0] == loci:\n",
    "            shap_values_SNP.append(1)\n",
    "        else:\n",
    "            shap_values_SNP.append(0)\n",
    "        counter += 1\n",
    "    \n",
    "    percent = sum(shap_values_SNP) / len(shap_values_SNP) * 100\n",
    "    \n",
    "    n = len(shap_values_SNP)\n",
    "    m = mean(shap_values_SNP)\n",
    "    std_err = sem(shap_values_SNP)\n",
    "    confidence_int = std_err * t.ppf((1 + confidence) / 2, n - 1)\n",
    "    \n",
    "    return percent, confidence_int\n",
    "    \n",
    "\n",
    "def shap_acc_RFR_var(samples_n, loci_m, var_g, var_e, number_trials):\n",
    "    shap_values_SNP = []\n",
    "    counter = 0\n",
    "    while counter != number_trials:\n",
    "        G, loci = simulate_genotype_and_phenotype_var(samples_n,loci_m, var_g , var_e)\n",
    "        shap_values_holder, x_train = shap_RFR_tree_train(G)\n",
    "        max_holder = max_mean_feature(shap_values_holder)\n",
    "        if max_holder[0] == loci:\n",
    "            shap_values_SNP.append(1)\n",
    "        else:\n",
    "            shap_values_SNP.append(0)\n",
    "        counter += 1\n",
    "    percent = sum(shap_values_SNP) / len(shap_values_SNP) * 100\n",
    "    confidence_int = 1\n",
    "    return percent, confidence_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Line Plots\n",
    "def plot_shap_values_RFR_line_multiple(samples_n, loci_m, range_values_g, range_values_e, number_trials, name = 'nameme', data_type = 'set'):\n",
    "    \n",
    "    increment_g = 1/range_values_g\n",
    "    increment_e = 1/range_values_e\n",
    "    holderg = 0\n",
    "    holdere = 0\n",
    "    g_vals = [0]\n",
    "    e_vals = [0]\n",
    "    \n",
    "#     for x in range(1, range_values_g):\n",
    "#         g_vals.append(holderg + increment_g)\n",
    "#         holderg = holderg + increment_g\n",
    "        \n",
    "    for x in range(1, range_values_e):\n",
    "        e_vals.append(holdere + increment_e)\n",
    "        holdere = holdere + increment_e\n",
    "    \n",
    "    \n",
    "    shap_values_SNP = []\n",
    "    \n",
    "    if data_type == 'set':\n",
    "        for y in range(0, range_values_e):\n",
    "            shap_values_SNP_holder = []\n",
    "            for x in range(0,1):\n",
    "                percent, confidence_int = shap_acc_RFR_set(samples_n, loci_m, 0, e_vals[y], number_trials)\n",
    "                shap_values_SNP_holder.append(percent)\n",
    "            shap_values_SNP.append(shap_values_SNP_holder)\n",
    "    elif data_type == 'var':\n",
    "        for y in range(0, range_values_e):\n",
    "            shap_values_SNP_holder = []\n",
    "            for x in range(0,1):\n",
    "                percent, confidence_int = shap_acc_RFR_var(samples_n, loci_m, 0, e_vals[y], number_trials)\n",
    "                shap_values_SNP_holder.append(percent)\n",
    "            shap_values_SNP.append(shap_values_SNP_holder)\n",
    "\n",
    "\n",
    "    return g_vals,shap_values_SNP,e_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples_n = 1000\n",
    "loci_m = 20\n",
    "range_values_g = 10\n",
    "range_values_e = 5\n",
    "number_trials = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb6840be87e427eb83d8a01855912c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acdd8f3615a94569b62851bd02b65f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf0336a02ea42d183110f8e058441dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38b8d2e93e34b5d9dbd1082e8a428db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5025bea79936451f92b5540c3558476b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "g_vals,shap_values_SNP,e_vals = plot_shap_values_RFR_line_multiple(samples_n, loci_m, range_values_g, range_values_e, number_trials,'RFR_One_Loci_fixed_var', data_type = 'var' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/u/home/k/kevindel/project-ngarud/Kevin_BIG_Summer_Code/lasso_LR_oneloci/results/lasso_LR_SHAP_oneloci_0', 'wb') as fp:\n",
    "    pickle.dump(shap_values_SNP, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
