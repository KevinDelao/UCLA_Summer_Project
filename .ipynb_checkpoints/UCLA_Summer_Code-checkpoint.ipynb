{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import shap\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import randrange\n",
    "from sklearn import linear_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# corr_list = []\n",
    "# for i in range(1,100):\n",
    "#     f_M = np.random.uniform(0,1,5)\n",
    "#     G = np.random.binomial(n=2,p = f_M, size = (100,5))\n",
    "# #     G = preprocessing.scale(G, axis=0)\n",
    "#     G = pd.DataFrame(G)\n",
    "#     corr  = G.corr()\n",
    "#     corr_list.append(corr)\n",
    "# with open('/Users/kevin/Downloads/Correlations_100', 'wb') as fp:\n",
    "#     pickle.dump(corr_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open ('/Users/kevin/Downloads/Correlations_100', 'rb') as fp:\n",
    "#     corr2list = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Loci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trait_simulation_oneloci(samples_n, loci_m,var_g,var_e):\n",
    "    f_M = np.random.uniform(0,1,loci_m)\n",
    "    G = np.random.binomial(n=2,p = f_M, size = (samples_n,loci_m))\n",
    "    G = preprocessing.scale(G, axis=0)\n",
    "    loci =random.randint(0,loci_m-1)\n",
    "    print(loci)\n",
    "    SNP = G[:,loci]\n",
    "    individuals = len(SNP)\n",
    "    mean = 0 \n",
    "    sigma_b = sqrt(var_g)\n",
    "    sigma_e = sqrt(var_e)\n",
    "    b_i = np.random.normal(0, sigma_b)\n",
    "    Y_n = np.zeros((individuals, 1))\n",
    "    for k in range(0, individuals):\n",
    "        #each individual will have a random e_j(noise) value\n",
    "        e_j = np.random.normal(0, sigma_e)\n",
    "        #G_ij will be the jth individual from our SNP for the loci of choce\n",
    "        G_ij  = SNP[k]\n",
    "        Y_j = b_i*G_ij + e_j\n",
    "        Y_n[k] = Y_j \n",
    "    y_max = np.max(Y_n)\n",
    "    y_max = abs(y_max)\n",
    "    Y_n = np.array(Y_n)\n",
    "    Y_n = Y_n/y_max\n",
    "    Y_n = Y_n.reshape(samples_n,1)\n",
    "    G = np.append(G, Y_n, axis=1)\n",
    "    H= var_g/(var_g+var_e)\n",
    "    G = np.append(G, Y_n, axis=1)\n",
    "    return G,samples_n,loci_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Loci Binary Traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trait_simulation_oneloci_binary(samples_n, loci_m,var_g,var_e):\n",
    "    f_M = np.random.uniform(0,1,loci_m)\n",
    "    G = np.random.binomial(n=2,p = f_M, size = (samples_n,loci_m))\n",
    "    G = preprocessing.scale(G, axis=0)\n",
    "    loci =random.randint(0,loci_m-1)\n",
    "    SNP = G[:,loci]\n",
    "    individuals = len(SNP)\n",
    "    mean = 0 \n",
    "    sigma_b = sqrt(var_g)\n",
    "    sigma_e = sqrt(var_e)\n",
    "    b_i = np.random.normal(0, sigma_b)\n",
    "    Y_n = np.zeros((individuals, 1))\n",
    "    for k in range(0, individuals):\n",
    "        #each individual will have a random e_j(noise) value\n",
    "        e_j = np.random.normal(0, sigma_e)\n",
    "        #G_ij will be the jth individual from our SNP for the loci of choce\n",
    "        G_ij  = SNP[k]\n",
    "        Y_j = b_i*G_ij + e_j\n",
    "        Y_n[k] = Y_j \n",
    "    #Before converting to categorical standerdize\n",
    "    Y_n = preprocessing.scale(Y_n, axis=0)\n",
    "    #Convert trait vector based on threshold here its point .2\n",
    "    #Y_n =  np.where(Y_n > 0.2, 1, 0)\n",
    "    #Alternative to threshold\n",
    "    Y_sorted = sorted(Y_n)\n",
    "    Ymed = np.median(Y_sorted);\n",
    "    Y_n =  np.where(Y_n > Ymed, 1, 0)\n",
    "    H= var_g/(var_g+var_e)\n",
    "    G = np.append(G, Y_n, axis=1)\n",
    "    return G,samples_n,loci_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Loci No Interaction Binary Traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trait_simulation_twolociBinary_nointer(samples_n, loci_m,var_g,var_e):\n",
    "    f_M = np.random.uniform(0,1,loci_m)\n",
    "    var_g = var_g/2\n",
    "    G = np.random.binomial(n=2,p = f_M, size = (samples_n,loci_m))\n",
    "    G = preprocessing.scale(G, axis=0)\n",
    "    #two random numbers without replacement\n",
    "    loci = random.sample(range(0,loci_m), 2)\n",
    "    SNP1 = G[:,loci[0]]\n",
    "    SNP2 = G[:,loci[1]]\n",
    "    #doesnt matter which SNP we choose from since their both same length\n",
    "    individuals = len(SNP1)\n",
    "    mean = 0 \n",
    "    sigma_b = sqrt(var_g)\n",
    "    sigma_e = sqrt(var_e)\n",
    "    b_i_SNP1 = np.random.normal(0, sigma_b)\n",
    "    b_i_SNP2 = np.random.normal(0, sigma_b)\n",
    "    Y_n = np.zeros((individuals, 1))\n",
    "    for k in range(0, individuals):\n",
    "        #each individual will have a random e_j(noise) value\n",
    "        e_j = np.random.normal(0, sigma_e)\n",
    "        #G1 and G2 will be the jth individual from our SNP1 and SNP 2 for the loci\n",
    "        G1 = SNP1[k]\n",
    "        G2 = SNP2[k]\n",
    "        Y_j = (G1*b_i_SNP1)+(G2*b_i_SNP2) + e_j\n",
    "        Y_n[k] = Y_j \n",
    "    Y_n = preprocessing.scale(Y_n, axis=0)\n",
    "    #Convert trait vector based on threshold here its point .2\n",
    "    #Y_n =  np.where(Y_n > 0.2, 1, 0)\n",
    "    #Alternative to threshold\n",
    "    Y_sorted = sorted(Y_n)\n",
    "    Ymed = np.median(Y_sorted);\n",
    "    Y_n =  np.where(Y_n > Ymed, 1, 0)\n",
    "    H= var_g/(var_g+var_e)\n",
    "    G = np.append(G, Y_n, axis=1)\n",
    "    return G,samples_n,loci_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Loci No Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trait_simulation_twoloci_nointer(samples_n, loci_m,var_g,var_e):\n",
    "    f_M = np.random.uniform(0,1,loci_m)\n",
    "    var_g = var_g/2\n",
    "    G = np.random.binomial(n=2,p = f_M, size = (samples_n,loci_m))\n",
    "    G = preprocessing.scale(G, axis=0)\n",
    "    #two random numbers without replacement\n",
    "    loci = random.sample(range(0,loci_m), 2)\n",
    "    SNP1 = G[:,loci[0]]\n",
    "    SNP2 = G[:,loci[1]]\n",
    "    print(SNP2[0:30])\n",
    "    #doesnt matter which SNP we choose from since their both same length\n",
    "    individuals = len(SNP1)\n",
    "    mean = 0 \n",
    "    sigma_b = sqrt(var_g)\n",
    "    sigma_e = sqrt(var_e)\n",
    "    b_i_SNP1 = np.random.normal(0, sigma_b)\n",
    "    b_i_SNP2 = np.random.normal(0, sigma_b)\n",
    "    Y_n = np.zeros((individuals, 1))\n",
    "    for k in range(0, individuals):\n",
    "        #each individual will have a random e_j(noise) value\n",
    "        e_j = np.random.normal(0, sigma_e)\n",
    "        #G1 and G2 will be the jth individual from our SNP1 and SNP 2 for the loci\n",
    "        G1 = SNP1[k]\n",
    "        G2 = SNP2[k]\n",
    "        Y_j = (G1*b_i_SNP1)+(G2*b_i_SNP2) + e_j\n",
    "        Y_n[k] = Y_j \n",
    "    H= var_g/(var_g+var_e)\n",
    "    G = np.append(G, Y_n, axis=1)\n",
    "    return G,samples_n,loci_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Loci  Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate base phenotype values\n",
    "def trait_simulation_twoloci_inter(samples_n,loci_m,var_g,var_e, n_causal_SNPs,b12_event,scalings = True):\n",
    "    #create allele frequencies\n",
    "    f_M = np.random.uniform(0,1,loci_m)\n",
    "    #create G matrix bases on allele frequencies\n",
    "    G = np.random.binomial(n=2,p = f_M, size = (samples_n,loci_m))\n",
    "    #scale or not depending on input, default is True\n",
    "    if scalings: \n",
    "        G = preprocessing.scale(G, axis=0)\n",
    "    #rows are the loci so each person has a row of different loci\n",
    "    individuals = len(G)    \n",
    "    sigma_e = sqrt(var_e)\n",
    "    sigma_b = sqrt(var_g/n_causal_SNPs)\n",
    "    #b_i = loci effect on phenotype\n",
    "    b_1 = np.random.normal(0, sigma_b)\n",
    "    b_2 = np.random.normal(0, sigma_b)\n",
    "    loci =random.sample(range(0, loci_m), 2)\n",
    "    print(loci[0])\n",
    "    print(loci[1])\n",
    "\n",
    "    SNP1 = G[:,loci[0]]\n",
    "    SNP2 = G[:,loci[1]]\n",
    "    individuals = len(SNP1)    \n",
    "    #rows are the loci so each person has a row of different loci\n",
    "    Y_n = np.zeros((individuals, 1));\n",
    "    \n",
    "    #depending on b1_event b12 will be different\n",
    "    # if 0 then b12 has no effect\n",
    "    if (b12_event == 0):\n",
    "        b_12 = 0\n",
    "    #if 1 then Random Combined Effect\n",
    "    elif(b12_event == 1):\n",
    "        b_12 = np.random.normal(0, sigma_b)\n",
    "    #if 2 then: 0 < b_12 < b1\n",
    "    elif(b12_event == 2):\n",
    "        b_12 = random.uniform(0, abs(b_1))\n",
    "    #if 3 then: 0 < b_12 < b2\n",
    "    elif(b12_event == 3):\n",
    "        b_12 = random.uniform(0, abs(b_2))\n",
    "    #if 4 then: b_1 + b_2 < b_12\n",
    "    elif(b12_event == 4):\n",
    "        b_12 = random.uniform(abs(b_1) + abs(b_2), 1)\n",
    "    #if 5 then: b_12 < 0\n",
    "    elif(b12_event == 5):\n",
    "        b_12 = random.uniform(-1 * sigma_b, 0)\n",
    "             \n",
    "    #create phenotype vector\n",
    "    for k in range(0, individuals):\n",
    "        #each individual will have a random e_j(noise) value\n",
    "        e_j = np.random.normal(0, sigma_e)\n",
    "        #G_ij will be the jth individual from our SNP for the loci of choice\n",
    "        G_ij1  = SNP1[k]\n",
    "        G_ij2  = SNP2[k]\n",
    "        Y_j = (b_1*G_ij1) + (b_2*G_ij2) + (b_12 * (G_ij1 * G_ij2))+ e_j \n",
    "        Y_n[k] = Y_j \n",
    "    #add Y traits to G matrix\n",
    "    G = np.append(G, Y_n, axis=1)\n",
    "    return G, loci_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Genotype\n",
    "def generate_genotype(n, m, processing = True):\n",
    "    f_M = np.random.uniform(0,1,m)\n",
    "    G = np.random.binomial(n=2,p = f_M, size =  (n,m))\n",
    "    if processing: \n",
    "        G = preprocessing.scale(G, axis=0)\n",
    "    return G\n",
    "\n",
    "#Generate base phenotype values\n",
    "def generate_base_pheno_values(G, var_g, var_e, n_causal_SNPs):\n",
    "    #rows are the loci so each person has a row of different loci\n",
    "    individuals = len(G)    \n",
    "    sigma_e = sqrt(var_e)\n",
    "    sigma_b = sqrt(var_g/n_causal_SNPs)\n",
    "    #b_i = loci effect on phenotype\n",
    "    b_1 = np.random.normal(0, sigma_b)\n",
    "    b_2 = np.random.normal(0, sigma_b)\n",
    "    \n",
    "    loci =random.sample(range(0, len(G[0])), 2)\n",
    "    SNP1 = G[:,loci[0]]\n",
    "    SNP2 = G[:,loci[1]]\n",
    "    return b_1, b_2, SNP1, SNP2, sigma_e, sigma_b\n",
    "\n",
    "def generate_phenotype_additive(b_1, b_2, SNP1, SNP2, sigma_e, b_12):\n",
    "    individuals = len(SNP1)    \n",
    "    #rows are the loci so each person has a row of different loci\n",
    "    Y_n = np.zeros((individuals, 1));\n",
    "    for k in range(0, individuals):\n",
    "        #each individual will have a random e_j(noise) value\n",
    "#         e_j = np.random.normal(0, sigma_e)\n",
    "        e_j =0\n",
    "        \n",
    "        #G_ij will be the jth individual from our SNP for the loci of choice\n",
    "        G_ij1  = SNP1[k]\n",
    "        G_ij2  = SNP2[k]\n",
    "        Y_j = (b_1*G_ij1) + (b_2*G_ij2) + (b_12 *( G_ij1 * G_ij2))+ e_j \n",
    "        Y_n[k] = Y_j \n",
    "    return Y_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_interact_avg(shap_values,x_test,forReg):\n",
    "    shap_values = np.array(shap_values)\n",
    "    avg_shap = []\n",
    "    for i in range(0,len(shap_values[0])):\n",
    "        shap2 = np.mean(abs(shap_values[:,i]))\n",
    "        avg_shap.append(shap2)\n",
    "    temp1 = np.asarray(avg_shap)     \n",
    "    indices = temp1.argsort()[-4:][::-1]\n",
    "    index1 = int(indices[0])\n",
    "    index2 = int(indices[1])\n",
    "    shap_interaction_values = shap.TreeExplainer(forReg).shap_interaction_values(x_test)\n",
    "    shap_avg = np.mean(shap_interaction_values[:,index1,index2])\n",
    "    return shap_avg,indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ints(shap_interaction_values, indices,shap_avgL):\n",
    "    loci_plots = np.zeros((len(shap_interaction_values),6))\n",
    "    loci_plots[:,0] = shap_interaction_values[:,indices[0],indices[1]]\n",
    "    loci_plots[:,1] = shap_interaction_values[:,indices[0],indices[2]]\n",
    "    loci_plots[:,2] = shap_interaction_values[:,indices[0],indices[3]]\n",
    "    loci_plots[:,3] = shap_interaction_values[:,indices[1],indices[2]]\n",
    "    loci_plots[:,4] = shap_interaction_values[:,indices[1],indices[3]]\n",
    "    loci_plots[:,5] = shap_interaction_values[:,indices[2],indices[3]]\n",
    "    data_to_plot =loci_plots\n",
    "    positions = np.arange(6) + 1\n",
    "    fig, ax = plt.subplots(1,1, figsize=(9,4))\n",
    "    loci_pairs = ['Loci '+str(indices[0])+'&'+str(indices[1]), 'Loci '+str(indices[0])+'&'+str(indices[2]), \n",
    "                  'Loci '+str(indices[0])+'&'+str(indices[3]), \n",
    "                  'Loci '+str(indices[1])+'&'+str(indices[2]), \n",
    "                  'Loci '+str(indices[1])+'&'+str(indices[3]),'Loci '+str(indices[2])+'&'+str(indices[3])]\n",
    "    bp = ax.boxplot(data_to_plot, positions=positions,showfliers=False,whis=None,whiskerprops=None)\n",
    "    means = [np.mean(data) for data in data_to_plot.T]\n",
    "    ax.plot(positions, means, 'rs')\n",
    "    ax.set_xticklabels(loci_pairs, fontdict=None, minor=False)\n",
    "    ax.set_title(\"Average SHAP Interaction Between Loci, e = 0\")\n",
    "    ax.set_ylabel(\"SHAP Interaction Value\")\n",
    "    ax.set_xlabel(\"Loci Pairs\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generate_genotype(1000, 50)\n",
    "b_1, b_2, SNP1, SNP2, sigma_e, sigma_b = generate_base_pheno_values(G, 0.9, .2, 2)\n",
    "b_1 = .5\n",
    "b_2 = .5\n",
    "\n",
    "Y_lists = []\n",
    "#No Effect\n",
    "b_12 = 0\n",
    "Z = generate_phenotype_additive(b_1, b_2, SNP1, SNP2, sigma_e, b_12)\n",
    "Y_lists.append(Z)\n",
    "\n",
    "#Random Combined Effect\n",
    "# b_12 = np.random.normal(0, sigma_b)\n",
    "b_12 = 2\n",
    "A = generate_phenotype_additive(b_1, b_2, SNP1, SNP2, sigma_e, b_12)\n",
    "Y_lists.append(A)\n",
    "\n",
    "#0 < b_12 < b1\n",
    "# b_12 = random.uniform(0, abs(b_1))\n",
    "b_12 = -2\n",
    "B = generate_phenotype_additive(b_1, b_2, SNP1, SNP2, sigma_e, b_12)\n",
    "Y_lists.append(B)\n",
    "\n",
    "#0 < b_12 < b2\n",
    "# b_12 = random.uniform(0, abs(b_2))\n",
    "b_12 = 4\n",
    "C = generate_phenotype_additive(b_1, b_2, SNP1, SNP2, sigma_e, b_12)\n",
    "Y_lists.append(C)\n",
    "\n",
    "\n",
    "#b_1 + b_2 < b_12\n",
    "# b_12 = random.uniform(abs(b_1) + abs(b_2), 1)\n",
    "b_12 = -4\n",
    "D = generate_phenotype_additive(b_1, b_2, SNP1, SNP2, sigma_e, b_12)\n",
    "Y_lists.append(D)\n",
    "\n",
    "#b_12 < 0\n",
    "# b_12 = random.uniform(-1 * sigma_b, 0)\n",
    "# E = generate_phenotype_additive(b_1, b_2, SNP1, SNP2, sigma_e, b_12)\n",
    "# Y_lists.append(E)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G0 to G5 are for b12 values above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "G0 = np.append(G, Y_lists[0], axis=1)\n",
    "G1 = np.append(G, Y_lists[1], axis=1)\n",
    "G2 = np.append(G, Y_lists[2], axis=1)\n",
    "G3 = np.append(G, Y_lists[3], axis=1)\n",
    "G4 = np.append(G, Y_lists[4], axis=1)\n",
    "# G5 = np.append(G, Y_lists[5], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G_oneloci is for one loci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "G_oneloci, samples_n,loci_m = trait_simulation_oneloci(1000,20,.9,.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.32587191e-01, -3.43112413e-01, -3.66677119e-01,  2.89945498e-01,\n",
       "       -2.06756556e-01, -4.37809946e-01,  8.73268517e-01, -8.28149028e-02,\n",
       "       -5.42665593e-02,  6.23390556e-01, -1.94449560e-01, -1.18488476e-02,\n",
       "       -1.40791103e-01, -5.27577024e-01, -5.45665199e-02, -8.25726099e-03,\n",
       "       -4.85708756e-02, -5.34216706e-01,  4.78845924e-01, -5.79969155e-01,\n",
       "       -4.33484479e-02,  2.60491662e-01, -1.05694358e-01, -3.27217297e-01,\n",
       "       -5.11596272e-01, -5.68510704e-01,  3.25946466e-01, -4.61925019e-01,\n",
       "        5.42463108e-01,  2.47809175e-01,  3.44575741e-01, -4.04895908e-01,\n",
       "       -2.58001708e-01,  1.78663241e-01, -4.92864394e-01, -2.21870479e-01,\n",
       "        4.57268798e-01, -1.65812656e-01,  4.95650551e-01, -3.05804784e-01,\n",
       "        2.78282038e-01,  3.21392754e-01,  4.94544681e-01,  3.52877261e-01,\n",
       "       -7.31206309e-01, -8.06504206e-02, -1.50818949e-01,  4.02010309e-01,\n",
       "        8.85226856e-03,  3.98201866e-01,  2.20473390e-01,  1.22073151e-02,\n",
       "       -7.38200779e-02,  1.41644032e-01,  4.55578260e-01, -4.92099794e-01,\n",
       "       -8.76579317e-02,  2.87359580e-01, -2.45386699e-01,  2.17701374e-01,\n",
       "        1.29406533e-01, -1.28731208e-01,  4.71804722e-01, -7.05474491e-02,\n",
       "        2.91390436e-01, -6.01251600e-01,  1.34696100e-01, -1.35735056e-01,\n",
       "       -2.35830207e-01,  1.14139746e-01,  1.50582195e-02, -2.30016634e-01,\n",
       "       -3.81029152e-01,  1.43706524e-02,  2.43432925e-01, -3.88432331e-01,\n",
       "       -1.17655051e-01,  1.54668953e-01, -3.89723273e-01, -1.42868060e-01,\n",
       "        4.09793731e-01, -8.64962145e-02, -2.77429545e-01,  2.65634096e-01,\n",
       "        3.80981464e-01,  3.31366105e-01,  5.95513146e-01, -2.05931600e-01,\n",
       "        6.50311817e-02, -5.72681842e-01,  4.24038655e-01,  1.23408837e-01,\n",
       "       -3.69294079e-01, -7.74076061e-02,  2.18128260e-01, -2.42346950e-01,\n",
       "        7.91850613e-02, -4.97556750e-02,  2.89387305e-01,  2.46429790e-01,\n",
       "       -2.70783487e-01,  5.00368994e-01, -9.86480758e-02,  2.45363828e-01,\n",
       "        2.12407179e-01, -3.97031003e-01,  2.15667552e-01, -5.18761428e-01,\n",
       "       -3.12565156e-01,  1.22218660e-01,  3.06935411e-01, -3.76741823e-01,\n",
       "       -1.21211866e-01,  1.42561552e-01,  2.34284413e-01, -2.51527967e-01,\n",
       "        4.96775243e-01, -1.96601444e-01, -1.03376716e-02, -6.12667679e-02,\n",
       "       -2.60160880e-01, -1.91123147e-01, -4.36053143e-01,  3.47816881e-02,\n",
       "       -1.12855279e-01, -5.83036551e-01, -6.61582977e-01, -2.08837947e-02,\n",
       "       -2.63214229e-01, -3.93809130e-01,  5.90978661e-02, -2.31225413e-01,\n",
       "       -2.49850019e-02, -1.77237337e-01, -2.83987623e-01,  8.57611542e-02,\n",
       "       -8.32928641e-02,  1.73123171e-01,  4.58428719e-01,  3.48043547e-01,\n",
       "        4.24795825e-01,  2.00732292e-01,  1.38393813e-01, -1.76646162e-01,\n",
       "        6.41310676e-01, -3.90936912e-01, -1.11544944e-01, -1.27061020e-01,\n",
       "       -3.04031334e-02, -9.06766443e-02,  5.81916123e-01,  5.19173985e-02,\n",
       "        9.11812862e-02,  6.94370410e-02, -2.01845536e-02,  1.06662826e-01,\n",
       "        7.10785769e-02,  1.45005108e-01, -8.23394609e-01, -5.09626023e-01,\n",
       "        2.84299352e-01,  6.52905236e-04, -8.72069057e-03,  1.93662702e-01,\n",
       "        7.67111431e-03, -5.29154536e-01, -2.19374140e-01, -1.44888357e-01,\n",
       "        4.31660996e-01,  2.12855860e-01, -1.81459274e-01,  4.58382780e-01,\n",
       "       -1.93812805e-01, -1.20296022e-01,  3.48929459e-01, -3.36412755e-01,\n",
       "       -3.53943238e-01,  1.54160050e-01, -1.42623474e-01,  4.85292340e-02,\n",
       "       -3.50026031e-01,  6.76568798e-01,  9.95105414e-02, -2.64578665e-01,\n",
       "        2.84766850e-01, -7.85531303e-02, -8.29512409e-02,  1.41529391e-01,\n",
       "       -1.63562235e-01, -5.11916228e-01,  5.80673270e-03,  2.46782910e-01,\n",
       "        4.89972622e-01, -3.74270942e-02, -1.98705697e-01, -1.78995211e-01,\n",
       "       -1.22453462e-01, -6.58007478e-01, -5.20735687e-01, -2.61179428e-01,\n",
       "       -5.62740547e-01, -5.19588565e-01,  3.15949872e-01,  3.09857136e-01,\n",
       "       -3.03526974e-01,  1.36357901e-01,  7.48996958e-01,  6.37931789e-01,\n",
       "       -1.60892314e-01, -2.19696024e-02, -4.31619661e-01, -3.88569193e-01,\n",
       "       -4.42878818e-01,  6.15645463e-01,  7.31531007e-02, -1.72264221e-01,\n",
       "       -7.55590521e-02, -4.17657648e-01, -1.20927478e-01,  4.83646536e-01,\n",
       "       -4.87456715e-01,  1.25659500e-01, -3.36912479e-01,  1.86952642e-01,\n",
       "       -1.46033006e-01,  1.22392964e-02,  1.34447524e-02,  3.94439669e-01,\n",
       "       -2.98838915e-01, -4.90062220e-01, -1.36625461e-01,  2.24924123e-02,\n",
       "       -3.01155223e-01,  4.02027852e-01, -1.82324224e-01, -1.91368869e-02,\n",
       "       -6.24232614e-02, -5.22835091e-01, -1.58316735e-01,  1.70195587e-02,\n",
       "       -4.23100017e-01,  3.69797909e-01,  7.02128456e-03, -4.08027482e-01,\n",
       "       -6.80057881e-01,  1.18504482e-01,  7.17606989e-02,  1.74331125e-01,\n",
       "        4.03817212e-01,  5.37301093e-01, -2.61911280e-01,  2.77847155e-01,\n",
       "        4.25283378e-01, -4.21458784e-01,  5.17460272e-01, -4.28526871e-01,\n",
       "        1.67880393e-02,  2.58926530e-01, -7.56910006e-02,  1.71441817e-01,\n",
       "        2.45186089e-01, -2.65087134e-03,  5.57372743e-01,  3.15266582e-01,\n",
       "       -1.48807324e-01, -4.11100120e-01,  2.67100572e-01,  3.62932107e-02,\n",
       "        3.57516882e-01, -2.09334415e-01, -1.22429833e-01, -6.49075732e-03,\n",
       "       -4.73832216e-03,  3.57550829e-02,  2.05516270e-01, -3.27025493e-01,\n",
       "        7.38433725e-02, -3.23395784e-01, -2.37558480e-01, -4.21120248e-02,\n",
       "       -2.15718837e-01, -6.80110111e-01, -8.32381000e-02,  3.17373728e-01,\n",
       "       -1.03338038e-01,  1.17450073e-01, -6.29058762e-02, -2.35771838e-02,\n",
       "       -1.99302654e-01,  9.84108798e-02, -1.64546407e-02, -4.77759974e-01,\n",
       "       -9.33219196e-02, -2.45822097e-01, -5.14773868e-02, -3.33494512e-01,\n",
       "        2.53291779e-02,  3.08656568e-01,  5.48385238e-01, -3.63718942e-01,\n",
       "       -3.35591830e-01,  2.39948682e-01,  5.57604052e-01, -1.45839712e-01,\n",
       "        2.46053642e-01, -1.50818659e-01, -2.72910644e-01, -3.31153093e-01,\n",
       "        4.54612317e-02, -3.69733900e-01, -7.42023471e-03, -1.64981478e-02,\n",
       "       -1.98005595e-01,  3.13614696e-01,  2.69608346e-01, -1.03992217e-01,\n",
       "       -1.90667870e-01, -1.44025706e-01, -4.49945733e-01,  6.76174524e-02,\n",
       "        3.00295883e-01, -1.98324407e-01,  3.13726794e-01, -4.25974205e-01,\n",
       "       -6.98406499e-03,  3.96340872e-02,  1.67074889e-01, -2.48289130e-01,\n",
       "        2.32873108e-01, -1.95045757e-02, -2.08970912e-01,  2.46187642e-02,\n",
       "        1.05410750e-01, -5.92487643e-01,  1.03482486e-01, -1.94569325e-01,\n",
       "       -3.55135621e-01,  3.59046134e-01, -2.51616977e-01,  2.00188310e-01,\n",
       "       -3.63670274e-01,  7.22830875e-02, -2.56092637e-01, -1.34785262e-01,\n",
       "        2.94317872e-01, -2.69552835e-01, -9.71331937e-03,  3.54066238e-01,\n",
       "       -3.62673937e-01,  1.44634150e-01,  4.61235293e-01, -2.79821899e-01,\n",
       "        3.30705793e-01, -4.59944566e-02,  5.00098440e-01, -1.02811738e-01,\n",
       "        2.35651731e-01, -1.87269283e-01, -9.89078544e-02,  3.31156250e-01,\n",
       "        3.28948036e-01, -4.14659905e-02,  3.68469729e-02, -3.63630786e-01,\n",
       "        1.16030942e-01,  2.09147616e-01, -4.71947296e-02, -3.90985880e-02,\n",
       "       -2.79399802e-02,  4.99730896e-02, -9.59281146e-02,  2.17378890e-01,\n",
       "       -7.11189171e-02, -3.93178045e-01,  9.89682283e-02,  3.77988745e-02,\n",
       "        1.95501036e-02, -3.76152000e-01, -7.40656421e-02, -2.64446322e-01,\n",
       "       -3.56928206e-01,  1.49108648e-01, -7.70920672e-02, -4.75461443e-01,\n",
       "       -2.42383049e-01,  1.19184455e-01, -2.40683587e-01, -9.37242153e-02,\n",
       "        1.24021305e-01,  3.80094262e-01, -7.64957578e-02, -1.67610829e-01,\n",
       "        3.29444695e-01,  3.61445843e-01, -2.02401425e-01, -2.60913062e-01,\n",
       "       -2.88117321e-01,  5.61024204e-02, -6.52034042e-01, -2.87645319e-02,\n",
       "        3.61812447e-01,  1.73769308e-01,  2.23286847e-01, -4.44658620e-02,\n",
       "        1.39428233e-01, -8.87370690e-02, -9.34031230e-02,  4.00740431e-01,\n",
       "        2.23576658e-01,  9.01005818e-02,  2.67077878e-01, -5.41537694e-01,\n",
       "       -2.04310814e-01,  3.86807542e-01, -2.44537781e-01,  4.63169299e-01,\n",
       "       -2.15834416e-02,  1.97566313e-01, -7.66353741e-02, -4.57721031e-01,\n",
       "        2.05343849e-01, -3.97514879e-01,  9.14626429e-02, -3.82278116e-01,\n",
       "       -4.99072538e-01, -3.77491618e-01,  4.05460735e-01,  2.36003457e-01,\n",
       "       -3.75222764e-01,  1.39244872e-01,  6.22373849e-03, -2.20352339e-03,\n",
       "       -7.46002064e-02,  2.22535459e-01,  2.28592819e-01, -3.42729931e-01,\n",
       "        3.68105161e-01,  2.03658373e-01,  5.57923410e-02,  2.37554382e-01,\n",
       "       -3.16760986e-01,  1.37062695e-02,  1.87277500e-01,  1.65246849e-01,\n",
       "        5.38873947e-01,  5.67555819e-01, -4.66643993e-01, -1.94218360e-01,\n",
       "        5.05878521e-01,  1.70178155e-01, -4.50879631e-01,  1.26992581e-02,\n",
       "        1.58804988e-02, -3.93204717e-01,  3.43856055e-01,  3.10102696e-01,\n",
       "        3.29300855e-01, -4.63917374e-01,  3.35528332e-01,  1.89147431e-01,\n",
       "        4.49804687e-01, -2.31367303e-01, -4.51214271e-01, -2.39338785e-01,\n",
       "       -7.01991130e-01, -3.91788399e-01,  3.24983747e-01,  2.37450519e-01,\n",
       "        6.13354008e-02,  1.36031429e-01,  3.03891539e-01, -6.40831257e-02,\n",
       "       -1.85736051e-02,  9.25419761e-02, -5.24324535e-01,  2.08012760e-01,\n",
       "        2.94788406e-01, -7.29009094e-02, -7.54695443e-02,  2.21404840e-01,\n",
       "       -8.38388888e-02,  3.12718657e-01, -1.12985208e-01,  2.82739236e-01,\n",
       "       -3.63739374e-01,  3.84988569e-01,  2.50129896e-01, -3.51684180e-01,\n",
       "       -2.11181532e-01,  4.27949675e-01, -1.56480823e-02,  2.59611596e-01,\n",
       "       -1.55934785e-01,  1.82574781e-01,  5.04267348e-01, -3.42072539e-01,\n",
       "        4.41357121e-01, -8.01595206e-01,  4.20861150e-01, -6.36320541e-01,\n",
       "        2.09442822e-01,  4.05765698e-01,  3.75167722e-01, -2.79532422e-01,\n",
       "        3.22156253e-01, -2.16484109e-01, -1.76381596e-01, -6.27781434e-02,\n",
       "       -1.69716754e-01, -6.06349581e-01, -7.16784614e-02,  4.40560996e-01,\n",
       "        9.98954190e-02, -2.40670228e-01,  2.31395288e-01,  3.75932081e-01,\n",
       "        2.78084561e-01,  7.39177096e-01,  2.77038403e-01, -1.75391437e-01,\n",
       "        7.74573052e-02, -5.18548872e-01,  9.39268802e-03, -7.45994875e-02,\n",
       "        1.20289600e-01,  2.48809074e-01, -3.51542163e-01, -1.39045406e-01,\n",
       "        1.22505866e-01, -1.09898832e-01, -8.52606228e-02, -8.63242813e-02,\n",
       "       -1.57539208e-01,  7.92185833e-01,  1.64037462e-03, -3.36889029e-02,\n",
       "       -3.28948575e-01, -4.08061743e-01,  3.11801999e-01, -2.08292144e-01,\n",
       "       -3.35335051e-01,  6.55654031e-02, -3.27378538e-02,  4.54526205e-01,\n",
       "        2.91152304e-01,  2.29415808e-01, -2.28080930e-01,  2.61151990e-01,\n",
       "        1.22569809e-03, -2.43309422e-01,  3.23118933e-01, -6.73698332e-02,\n",
       "       -5.39886333e-01, -2.43281496e-01, -1.76624064e-01,  2.69637556e-01,\n",
       "        1.98771451e-01, -3.99110959e-01,  1.35048824e-01,  7.75930588e-02,\n",
       "        8.64221771e-03, -1.63066200e-01,  7.14001350e-01,  2.12078271e-01,\n",
       "        1.96698826e-01, -1.92572145e-02,  3.58103775e-02, -1.37151903e-01,\n",
       "       -2.52778300e-01, -3.87099498e-02, -4.82403110e-01,  1.30679955e-01,\n",
       "        9.44308568e-02, -2.44661883e-01,  3.91645796e-01,  2.35457549e-01,\n",
       "        4.44935084e-01, -4.29070420e-01,  1.11014545e-01, -2.51168847e-01,\n",
       "        2.53051476e-01,  2.41671841e-01, -1.05980028e-01,  7.07117343e-02,\n",
       "        3.67853632e-02, -3.14126352e-02, -2.24099561e-01, -1.23208640e-01,\n",
       "        1.38272016e-01,  6.87970167e-02, -3.88364816e-01, -5.25078062e-02,\n",
       "       -3.65187024e-02,  5.70987274e-03, -7.05951311e-02,  7.02177453e-02,\n",
       "        4.23901377e-01,  1.05176118e-01, -5.33770705e-02,  1.48192596e-01,\n",
       "        8.61153545e-02, -5.46132041e-01,  1.54135259e-01, -2.54638882e-01,\n",
       "        2.83982104e-01, -1.83194702e-01,  5.90997578e-01, -1.36570943e-01,\n",
       "       -2.57400131e-01, -8.23998534e-02,  1.36641287e-01,  1.00000000e+00,\n",
       "       -1.25689554e-01,  1.00326378e-01,  1.13664378e-01, -1.62991886e-01,\n",
       "       -5.25650951e-03, -6.40110905e-02,  6.96107836e-01, -1.33647896e-01,\n",
       "        1.33877297e-01, -4.51885403e-01, -9.61025255e-03,  5.78699515e-01,\n",
       "       -1.02746763e-01, -4.40254725e-01, -3.15981789e-01,  4.49350682e-01,\n",
       "        2.20415144e-01,  5.42546578e-02,  2.16449326e-01, -1.33215330e-01,\n",
       "        2.96429118e-01,  5.76163248e-03,  9.19263255e-02,  2.77305984e-01,\n",
       "       -4.81506102e-02, -9.11065296e-02, -3.25785445e-01,  3.74066974e-01,\n",
       "        2.57257020e-01,  5.24996613e-01, -1.63747327e-01, -2.51918524e-01,\n",
       "        2.06691951e-01,  7.86366605e-02, -2.16830633e-01, -3.96508758e-01,\n",
       "        7.85519748e-01,  5.13740275e-01, -7.81316725e-01, -2.03330112e-01,\n",
       "        1.17699459e-01, -2.16149321e-01, -3.48531982e-01, -1.26711703e-02,\n",
       "       -3.24197016e-01, -5.01771941e-01, -1.90783669e-01, -2.57428976e-01,\n",
       "        1.32505130e-02, -1.58864845e-01,  4.67047794e-01, -1.86102827e-01,\n",
       "       -5.73547661e-01,  6.19523263e-02,  3.22253574e-01, -3.56223064e-01,\n",
       "       -6.99004519e-02,  1.14964116e-01, -1.50821530e-01,  3.33429250e-01,\n",
       "       -4.15363847e-01,  9.16071781e-02, -1.16878798e-01,  4.19123977e-01,\n",
       "        2.60259061e-01,  6.39490793e-02,  7.35138473e-01,  2.35865827e-01,\n",
       "       -1.74123866e-01,  2.20559375e-01,  2.30968379e-01, -3.90803540e-02,\n",
       "        3.89959879e-02, -4.84931455e-01, -2.84719548e-01,  5.72518400e-01,\n",
       "       -4.03132593e-01, -1.64411721e-01,  1.81159342e-01,  7.25723159e-01,\n",
       "       -2.18416289e-01,  3.43383568e-01,  5.69536187e-01, -2.04393611e-01,\n",
       "        4.58604749e-01, -3.56835286e-01,  6.64038476e-02,  1.93796487e-01,\n",
       "       -2.53532134e-01,  2.75819508e-01,  5.33396564e-02,  2.50749448e-01,\n",
       "       -3.57161974e-01, -2.43541645e-02, -7.25877140e-02, -5.07585870e-01,\n",
       "        1.19324323e-01, -1.57001439e-01,  2.26005333e-01,  7.91939529e-02,\n",
       "       -4.32272075e-01, -3.18442132e-01, -2.09876679e-01,  6.45302305e-02,\n",
       "        1.33253549e-01, -1.80350694e-01, -2.47790848e-01,  6.54874920e-02,\n",
       "        3.87959963e-02, -3.66575970e-01, -1.86589723e-01, -8.19309226e-02,\n",
       "       -4.35395271e-01, -8.01951468e-02, -1.44072682e-01,  2.27243648e-01,\n",
       "       -5.80341550e-01,  2.53444172e-02, -1.51908635e-03,  5.80987004e-02,\n",
       "        2.57021805e-02,  4.01985820e-01, -2.12498619e-01,  1.51790442e-01,\n",
       "        2.30686897e-01, -1.89477197e-01,  1.26134371e-01, -2.77783345e-01,\n",
       "        1.01892944e-01, -2.30676515e-01,  4.32015367e-01, -2.07016818e-01,\n",
       "       -2.44520705e-01, -8.10539720e-02, -3.63343227e-02, -4.22223502e-01,\n",
       "        1.56694846e-01, -7.90197096e-03, -7.71826563e-02,  1.54804888e-01,\n",
       "       -8.09103405e-01,  3.03045726e-01, -9.54616101e-02, -4.66282014e-01,\n",
       "        2.44781617e-01, -2.77188139e-01,  9.18770682e-02,  4.55227531e-01,\n",
       "        7.28617805e-01,  5.30181605e-01,  4.94648482e-01,  3.88499750e-01,\n",
       "       -2.09634801e-01,  2.36095730e-01,  1.28151546e-01,  6.99922819e-02,\n",
       "       -4.50733116e-02, -5.91900683e-01, -4.88852019e-02,  1.36935931e-02,\n",
       "       -6.10759606e-01, -8.25455997e-02, -3.13550778e-01,  3.20957344e-01,\n",
       "        3.30176282e-01,  2.29335891e-01,  1.39413338e-01, -1.09168204e-01,\n",
       "       -1.10784981e-01,  5.21159296e-01,  1.08435835e-01,  9.03212030e-02,\n",
       "        2.14823005e-01,  2.98641149e-01,  4.55607358e-01, -1.49309347e-01,\n",
       "       -8.24149763e-02, -1.91497774e-01, -4.10136539e-01,  6.77708237e-01,\n",
       "        3.61224304e-01,  2.79612554e-02,  8.41897016e-02, -6.10102383e-01,\n",
       "        3.62358524e-01,  8.91409441e-02,  1.31349481e-01, -1.10290717e-01,\n",
       "       -6.09583226e-02, -4.80080041e-01, -1.29457400e-01,  5.18420628e-01,\n",
       "       -1.72738774e-01, -7.44244007e-02,  1.80304913e-01, -3.77261184e-01,\n",
       "        7.54311978e-02, -2.78125663e-01,  5.60947560e-02, -6.00978647e-02,\n",
       "        3.48666731e-01,  4.74532521e-01, -2.68672980e-01,  2.07336896e-01,\n",
       "       -3.86110937e-01, -1.04462696e-01,  4.60468703e-01, -1.14050072e-01,\n",
       "       -4.96070303e-01,  1.12347630e-01,  3.52328781e-01,  1.10693847e-01,\n",
       "        4.94373897e-01,  6.05901806e-04, -1.34108363e-01,  1.35844824e-01,\n",
       "       -1.86166410e-01,  2.68803834e-01, -3.38500151e-01,  8.19420776e-02,\n",
       "        6.25905489e-01, -2.37910792e-01,  1.20984596e-01,  2.04979408e-01,\n",
       "        4.03821057e-01, -1.67660986e-01, -4.01707542e-01, -2.20823770e-01,\n",
       "        4.07727041e-01,  3.82096023e-01,  4.29985858e-01,  1.70917332e-01,\n",
       "        3.14892471e-01,  3.64875470e-01,  1.81093498e-01,  4.33563446e-02,\n",
       "        1.66078917e-02,  2.47540284e-01,  1.39831775e-01, -4.08850506e-01,\n",
       "       -1.35366978e-01,  7.63009685e-01, -3.91447595e-01,  2.49230672e-01,\n",
       "        2.84016118e-01, -3.32958138e-01, -6.21100687e-01,  2.90571464e-01,\n",
       "        7.85372690e-02,  6.92944286e-02, -6.48395132e-01,  6.52320881e-01,\n",
       "       -3.89095580e-01, -2.34531368e-01, -5.44628690e-02,  1.48116402e-02,\n",
       "       -2.63095365e-01,  2.44019572e-01,  4.03846215e-01,  3.27151624e-02,\n",
       "       -6.17944353e-02, -3.51943709e-01,  2.48477950e-02,  6.19072205e-01,\n",
       "       -5.93835793e-02, -3.99119161e-01,  2.68933652e-01, -2.65431441e-01,\n",
       "        3.11513929e-02,  3.67342819e-01, -8.28563293e-02,  3.60087714e-01,\n",
       "       -1.11652716e-01, -3.93377782e-01, -2.72530248e-01, -4.61822077e-02,\n",
       "       -1.82553013e-01,  2.10881180e-01,  5.38363649e-02,  2.64021075e-01,\n",
       "       -2.97162305e-01,  1.26669511e-01,  9.93310211e-02, -3.09559150e-01,\n",
       "       -5.81712745e-01, -1.92047712e-01, -4.66199366e-01,  4.37488459e-01,\n",
       "        2.91809996e-01, -7.49535760e-02,  3.05519393e-01, -4.27193131e-01,\n",
       "       -5.57291229e-01, -3.76374969e-01, -1.04232981e-02,  1.21272532e-01,\n",
       "        1.44115653e-01,  4.46912558e-01, -8.78700219e-02,  3.57216617e-01,\n",
       "        4.86078414e-01,  3.47734216e-01, -1.90266997e-01, -2.00794996e-01,\n",
       "       -2.14705850e-01,  7.58238264e-01, -2.34871058e-01,  6.04808659e-02,\n",
       "        1.63231981e-01,  7.86996352e-03,  5.11329109e-01, -5.35974650e-01,\n",
       "       -6.34883144e-02, -1.94452409e-01, -2.90939732e-01,  3.41532002e-01,\n",
       "        2.69696207e-01,  6.70552613e-02,  7.53893183e-01, -3.53142263e-01,\n",
       "       -2.47693105e-01, -2.63180729e-01,  1.52420879e-01, -1.08084598e-01,\n",
       "        2.25453124e-02, -3.36776752e-02, -2.66741012e-01, -1.99909434e-01,\n",
       "       -1.95185883e-01, -7.54072155e-02,  2.97386083e-01, -1.68385532e-01,\n",
       "       -1.83784142e-01, -2.81639636e-01,  8.60641066e-02,  3.00537980e-01,\n",
       "       -1.27940223e-01, -1.88785051e-02,  1.07296420e-01, -9.70316184e-02,\n",
       "       -2.41497162e-01, -7.57996064e-02, -1.05397045e-01, -4.37605623e-01,\n",
       "        6.21493590e-01, -6.22193349e-01,  5.35555286e-02, -1.98377810e-01,\n",
       "        2.64342596e-01,  2.39864342e-01,  2.51389140e-01,  2.30987255e-01,\n",
       "       -1.95419687e-01, -4.24981675e-02, -8.63054531e-02,  2.19998761e-01,\n",
       "        1.84310354e-01, -2.47088153e-01, -2.94314176e-01,  2.74991831e-01,\n",
       "       -3.42662854e-01,  3.03992875e-01,  1.71181787e-01, -1.52874511e-01,\n",
       "        1.22102581e-01, -1.67979728e-01,  6.93856684e-01, -3.90122085e-01,\n",
       "       -2.20993521e-01, -2.66105893e-02,  2.01898741e-01, -6.37744926e-02,\n",
       "       -1.17910778e-01,  6.58219534e-02, -2.51604260e-03,  2.65354116e-01,\n",
       "        2.07200195e-01, -4.08724652e-01, -9.70939061e-02,  1.37265715e-01,\n",
       "       -2.08424224e-01,  7.22435898e-01, -2.37190928e-01,  3.38892703e-01,\n",
       "       -3.01442716e-01, -4.20967890e-01, -1.84962652e-01,  8.74842701e-02])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_oneloci[:,21]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G_oneloci_binary is for one loci, this has binary traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_oneloci_binary, samples_n,loci_m = trait_simulation_oneloci_binary(500,20,.7,.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G_twoloci_binary is for one loci, this has binary traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_twoloci_binary, samples_n,loci_m = trait_simulation_twolociBinary_nointer(500,20,.7,.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G_twoloci is for two loci no interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08109528  0.08109528  0.08109528  0.08109528  0.08109528 -1.39336435\n",
      "  0.08109528  0.08109528 -1.39336435  0.08109528  0.08109528  0.08109528\n",
      "  0.08109528 -1.39336435  1.55555491 -1.39336435  0.08109528  0.08109528\n",
      " -1.39336435  1.55555491 -1.39336435 -1.39336435  0.08109528  0.08109528\n",
      "  1.55555491  1.55555491  0.08109528 -1.39336435 -1.39336435  0.08109528]\n"
     ]
    }
   ],
   "source": [
    "G_twoloci, samples_n,loci_m = trait_simulation_twoloci_nointer(1000,40,.5,.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G_twointerloci is for two loci with interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "e_list = [0,.1,.2,.3,.4,.5,.6,.7,.8,.9]\n",
    "[float(m) for m in e_list]# #this is a list of list\n",
    "var_e = e_list[randrange(10)]\n",
    "G_twointerloci,loci_m = trait_simulation_twoloci_inter(1000,40,.5,var_e,2,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F_i distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #use this to see distribution of f_i frequency\n",
    "# bin_size = 20\n",
    "# count, bins, ignored = plt.hist(f_M, 20, facecolor='blue') \n",
    "\n",
    "# plt.xlabel('X [0,1]')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title(\"Uniform Distribution For Loci Frequency Bin size: \"+str(bin_size))\n",
    "# plt.axis([0, 1, 0, len(f_M]) # x_start, x_end, y_start, y_end\n",
    "# plt.grid(True)\n",
    "\n",
    "# plt.show(block = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into test and train\n",
    "X = G_oneloci[:,0:len(G_oneloci[0])-1]\n",
    "\n",
    "#last column is the appended Y vector we predicted\n",
    "y = G_oneloci[:,len(G_oneloci[0])-1]\n",
    "\n",
    "#split the data, 70% training\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the algorithm\n",
    "linReg = LinearRegression() \n",
    "linReg.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model on test data\n",
    "y_predict = linReg.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error = 0.0\n",
      "Mean squared error = 0.0\n",
      "Root Mean squared error = 0.0\n",
      "Median absolute error = 0.0\n",
      "Explain variance score = 1.0\n",
      "R2 score = 1.0\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the regression model\n",
    "print(\"Mean absolute error =\", round(metrics.mean_absolute_error(y_test, y_predict), 2))\n",
    "print(\"Mean squared error =\", round(metrics.mean_squared_error(y_test, y_predict), 2)) \n",
    "rmse = metrics.mean_squared_error(y_test, y_predict)\n",
    "print(\"Root Mean squared error =\", round(sqrt(rmse),2))\n",
    "print(\"Median absolute error =\", round(metrics.median_absolute_error(y_test, y_predict), 2)) \n",
    "print(\"Explain variance score =\", round(metrics.explained_variance_score(y_test, y_predict), 2)) \n",
    "print(\"R2 score =\", round(metrics.r2_score(y_test, y_predict), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction error plot\n",
    "diff = y_test - y_predict\n",
    "plt.hist(diff,bins = 30, color = 'blue')\n",
    "plt.title('Prediction Errors')\n",
    "plt.xlabel('Phenotype prediction error')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = []\n",
    "for i in range(0,19):\n",
    "    x_vals.append(x_train[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "index, value = max(enumerate(x_vals), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(linReg.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.std(x_train, 0)*linReg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "explainer = shap.KernelExplainer(linReg.predict, shap.sample(x_train,100))\n",
    "shap_values = explainer.shap_values(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, x_test, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values,x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Regression\n",
    "#initialize tree with a node depth of 10 and 50 decision trees\n",
    "forReg = RandomForestRegressor(max_depth=10, random_state=0, n_estimators=50)\n",
    "forReg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFR Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict2 = forReg.predict(x_test)\n",
    "#Evaluate the regression model\n",
    "print(\"Mean absolute error =\", round(metrics.mean_absolute_error(y_test, y_predict2), 2))\n",
    "print(\"Mean squared error =\", round(metrics.mean_squared_error(y_test, y_predict2), 2)) \n",
    "rmse = metrics.mean_squared_error(y_test, y_predict2)\n",
    "print(\"Root Mean squared error =\", round(sqrt(rmse),2))\n",
    "print(\"Median absolute error =\", round(metrics.median_absolute_error(y_test, y_predict2), 2)) \n",
    "print(\"Explain variance score =\", round(metrics.explained_variance_score(y_test, y_predict2), 2)) \n",
    "print(\"R2 score =\", round(metrics.r2_score(y_test, y_predict2), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFR Prediction Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = y_test - y_predict2\n",
    "plt.hist(diff,bins = 30, color = 'blue')\n",
    "plt.title('Prediction Errors')\n",
    "plt.xlabel('Phenotype prediction error')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFR SHAP Values and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "shap_values = shap.TreeExplainer(forReg).shap_values(x_train)\n",
    "# shap_values = shap.TreeExplainer(forReg).shap_values(x_train)\n",
    "shap.summary_plot(shap_values, x_test, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mean_shap_values(shap_values):\n",
    "#     if len(shap_values) == 2:\n",
    "#         mean_shap = [0] * len(shap_values[0][0])\n",
    "#         for shap_value in shap_values[0]:\n",
    "#             for x in range(0, len(shap_value)):\n",
    "#                 mean_shap[x] = mean_shap[x] + abs(shap_value[x])\n",
    "#         for x in range(0, len(shap_values[0])):\n",
    "#             mean_shap[x] = abs(mean_shap[x] / len(shap_values[0]))\n",
    "#     else:    \n",
    "#         mean_shap = [0] * len(shap_values[0])\n",
    "#         for shap_value in shap_values:\n",
    "#             for x in range(0, len(shap_value)):\n",
    "#                 mean_shap[x] = mean_shap[x] + abs(shap_value[x])\n",
    "#         for x in range(0, len(shap_values[0])):\n",
    "#             mean_shap[x] = abs(mean_shap[x] / len(shap_values[0]))\n",
    "#     return mean_shap                   \n",
    "\n",
    "# def max_mean_feature(shap_values):\n",
    "#     mean_shap = mean_shap_values(shap_values)\n",
    "#     return mean_shap.index(max(mean_shap)), mean_shap[mean_shap.index(max(mean_shap))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index, shap = max_mean_feature(shap_values)\n",
    "# shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_shap = []\n",
    "for i in range(0,len(shap_values[0])):\n",
    "    shap2 = np.mean(abs(shap_values[:,i]))\n",
    "    avg_shap.append(shap2)\n",
    "temp1 = np.asarray(avg_shap)     \n",
    "indices = temp1.argsort()[-1:][::-1]\n",
    "# loci1,loci2 = avg_shap[indices[0]],avg_shap[indices[1]]\n",
    "int(indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values,x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP Interaction Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap_interaction_values = shap.TreeExplainer(forReg).shap_interaction_values(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shap_interaction_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.summary_plot(shap_interaction_values, features=x_test, max_display=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_avg,indices = shap_interact_avg(shap_values,x_test,forReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SHAP_AVG_List(shap_interaction_values,indices):\n",
    "    shap_avgL = []\n",
    "    shap_avg = np.mean(shap_interaction_values[:,indices[0],indices[1]])\n",
    "\n",
    "    shap_avgL.append(shap_avg)\n",
    "    shap_avg = np.mean(shap_interaction_values[:,indices[0],indices[2]])\n",
    "\n",
    "    shap_avgL.append(shap_avg)\n",
    "    shap_avg = np.mean(shap_interaction_values[:,indices[0],indices[3]])\n",
    "\n",
    "    shap_avgL.append(shap_avg)\n",
    "    shap_avg = np.mean(shap_interaction_values[:,indices[1],indices[2]])\n",
    "\n",
    "    shap_avgL.append(shap_avg)\n",
    "    shap_avg = np.mean(shap_interaction_values[:,indices[1],indices[3]])\n",
    "\n",
    "    shap_avgL.append(shap_avg)\n",
    "    shap_avg = np.mean(shap_interaction_values[:,indices[2],indices[3]])\n",
    "\n",
    "    shap_avgL.append(shap_avg)\n",
    "    shap_interaction = shap_avgL\n",
    "    shap_interaction2 = np.asarray(shap_interaction).reshape((1, 6))\n",
    "    avg_shap_inter = pd.DataFrame(shap_interaction2)\n",
    "    avg_shap_inter.columns = ['Loci '+str(indices[0])+'&'+str(indices[1]), 'Loci '+str(indices[0])+'&'+str(indices[2]), \n",
    "                  'Loci '+str(indices[0])+'&'+str(indices[3]), \n",
    "                  'Loci '+str(indices[1])+'&'+str(indices[2]), \n",
    "                  'Loci '+str(indices[1])+'&'+str(indices[3]),'Loci '+str(indices[2])+'&'+str(indices[3])]\n",
    "    return avg_shap_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SHAP_Median_List(shap_interaction_values,indices):\n",
    "    shap_avgL = []\n",
    "    shap_avg = np.median(shap_interaction_values[:,indices[0],indices[1]])\n",
    "\n",
    "    shap_avgL.append(shap_avg)\n",
    "    shap_avg = np.median(shap_interaction_values[:,indices[0],indices[2]])\n",
    "\n",
    "    shap_avgL.append(shap_avg)\n",
    "    shap_avg = np.median(shap_interaction_values[:,indices[0],indices[3]])\n",
    "\n",
    "    shap_avgL.append(shap_avg)\n",
    "    shap_avg = np.median(shap_interaction_values[:,indices[1],indices[2]])\n",
    "\n",
    "    shap_avgL.append(shap_avg)\n",
    "    shap_avg = np.median(shap_interaction_values[:,indices[1],indices[3]])\n",
    "\n",
    "    shap_avgL.append(shap_avg)\n",
    "    shap_avg = np.median(shap_interaction_values[:,indices[2],indices[3]])\n",
    "\n",
    "    shap_avgL.append(shap_avg)\n",
    "    shap_interaction = shap_avgL\n",
    "    shap_interaction2 = np.asarray(shap_interaction).reshape((1, 6))\n",
    "    avg_shap_inter = pd.DataFrame(shap_interaction2)\n",
    "    avg_shap_inter.columns = ['Loci '+str(indices[0])+'&'+str(indices[1]), 'Loci '+str(indices[0])+'&'+str(indices[2]), \n",
    "                  'Loci '+str(indices[0])+'&'+str(indices[3]), \n",
    "                  'Loci '+str(indices[1])+'&'+str(indices[2]), \n",
    "                  'Loci '+str(indices[1])+'&'+str(indices[3]),'Loci '+str(indices[2])+'&'+str(indices[3])]\n",
    "    return avg_shap_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_avgL = SHAP_AVG_List(shap_interaction_values,indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_medianL = SHAP_Median_List(shap_interaction_values,indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_interaction_values, features=x_test, max_display=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_shap_inter2 = plot_ints(shap_interaction_values,indices,shap_avgL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_avgL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_medianL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"compact_dot\" is only used for SHAP interaction values.\n",
    "shap.summary_plot(shap_interaction_values, features=x_test, max_display=5,plot_type=\"compact_dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = shap_interaction_values.shape\n",
    "shap_interaction_values_2d = np.reshape(np.ravel(shap_interaction_values), (dim[0], dim[1]*dim[2]))\n",
    "\n",
    "# make all pairs of features\n",
    "x1 = pd.DataFrame(x_test)\n",
    "\n",
    "# make all pairs of features\n",
    "x2 = x1[np.repeat(x1.columns.tolist(), len(x1.columns))]\n",
    "x2.columns =  [str(i)+\":\"+str(j) for i in x1.columns for j in x1.columns]\n",
    "\n",
    "shap.summary_plot(shap_interaction_values_2d, x2, sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_logreg = LogisticRegression()\n",
    "my_logreg.fit(x_train, y_train)\n",
    "y_predict_lr = my_logreg.predict(x_test)\n",
    "score_lr = accuracy_score(y_test, y_predict_lr)\n",
    "print(\"Accuracy for Logistic Regressions was: \"+ str(score_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "explainer = shap.KernelExplainer(my_logreg.predict, shap.sample(x_train,50))\n",
    "shap_values = explainer.shap_values(x_train)\n",
    "# shap.force_plot(explainer.expected_value[0], shap_values[0], X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, x_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 8,705\n",
      "Trainable params: 8,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade tensorflow tensorflow-probability\n",
    "model = Sequential()\n",
    "hidden_nodes = len(X[0])+20 \n",
    "model.add(Dense( 256, activation='relu', input_dim = 32))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='relu', input_dim = 256))\n",
    "model.add(Dropout(0.25))\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "# model.fit(x_train, y_train, epochs=50, batch_size=16, verbose = 0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam',activation='relu',neurons=1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense( neurons, activation=activation, input_dim = 20))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation=activation, input_dim = neurons))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.compile(loss='mean_absolute_error', optimizer=optimizer)\n",
    "    return model\n",
    "    # model.fit(x_train, y_train, epochs=50, batch_size=16, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'mean_squared_error' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[1;34m(scoring)\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m                 \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSCORERS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mean_squared_error'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-ba129fe211e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mneurons\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mneurons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    652\u001b[0m         \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m         scorers, self.multimetric_ = _check_multimetric_scoring(\n\u001b[0m\u001b[0;32m    655\u001b[0m             self.estimator, scoring=self.scoring)\n\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_check_multimetric_scoring\u001b[1;34m(estimator, scoring)\u001b[0m\n\u001b[0;32m    473\u001b[0m     if callable(scoring) or scoring is None or isinstance(scoring,\n\u001b[0;32m    474\u001b[0m                                                           str):\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"score\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    403\u001b[0m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[0;32m    404\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[1;31m# Heuristic to ensure user has not passed a metric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[1;34m(scoring)\u001b[0m\n\u001b[0;32m    360\u001b[0m                 \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSCORERS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m             raise ValueError('%r is not a valid scoring value. '\n\u001b[0m\u001b[0;32m    363\u001b[0m                              \u001b[1;34m'Use sorted(sklearn.metrics.SCORERS.keys()) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m                              'to get valid options.' % scoring)\n",
      "\u001b[1;31mValueError\u001b[0m: 'mean_squared_error' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 25, 50]\n",
    "neurons = [10, 32, 64, 128, 256]\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(epochs=epochs,batch_size=batch_size,optimizer=optimizer,activation=activation,neurons =neurons)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=10,scoring='neg_mean_squared_error')\n",
    "grid_result = grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -17.482582 using {'activation': 'relu', 'batch_size': 20, 'epochs': 25, 'neurons': 256, 'optimizer': 'Adam'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'batch_size': 20,\n",
       " 'epochs': 25,\n",
       " 'neurons': 256,\n",
       " 'optimizer': 'Adam'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/kevin/Downloads/GridSearchCv_Initial', 'wb') as fp:\n",
    "    pickle.dump(grid_result.best_params_, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.DeepExplainer(model, x_train)\n",
    "shap_values = explainer.shap_values(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values = np.array(shap_values)\n",
    "# avg_shap = []\n",
    "# for i in range(0,len(shap_values[0])):\n",
    "#     shap2 = np.mean(abs(shap_values[:,i]))\n",
    "#     avg_shap.append(shap2)\n",
    "# temp1 = np.asarray(avg_shap)\n",
    "# indices = temp1.argsort()[-2:][::-1]\n",
    "# loci1,loci2 = avg_shap[indices[0]],avg_shap[indices[1]]\n",
    "# indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(32, activation='relu', input_dim = len(X[0])))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Dense(1, activation='relu', input_dim = 32))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.compile(loss='mean_absolute_error', optimizer='rmsprop')\n",
    "# model.fit(x_train, y_train, epochs=50, batch_size=16, verbose = 0)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss, test_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('NN Accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the regression model\n",
    "print(\"Mean absolute error =\", round(metrics.mean_absolute_error(y_test, y_predict), 2))\n",
    "print(\"Mean squared error =\", round(metrics.mean_squared_error(y_test, y_predict), 2)) \n",
    "rmse = metrics.mean_squared_error(y_test, y_predict)\n",
    "print(\"Root Mean squared error =\", round(sqrt(rmse),2))\n",
    "print(\"Median absolute error =\", round(metrics.median_absolute_error(y_test, y_predict), 2)) \n",
    "print(\"Explain variance score =\", round(metrics.explained_variance_score(y_test, y_predict), 2)) \n",
    "print(\"R2 score =\", round(metrics.r2_score(y_test, y_predict), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(x_test)\n",
    "y_predict = y_predict.reshape(len(y_predict))\n",
    "\n",
    "diff = y_test - y_predict\n",
    "plt.hist(diff,bins = 30, color = 'blue')\n",
    "plt.title('Prediction Errors')\n",
    "plt.xlabel('Phenotype prediction error')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, x_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half =  round((loci_m-1)/2)\n",
    "model = Sequential()\n",
    "model.add(Dense(half, activation='relu', input_dim = loci_m-1))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='relu', input_dim = half))\n",
    "model.add(Dropout(0.25))\n",
    "model.compile(loss='mean_absolute_error', optimizer='rmsprop')\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=16, verbose = 0)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half =  round((loci_m-1)/2)\n",
    "model = Sequential()\n",
    "model.add(Dense(half, activation='relu', input_dim = loci_m-1))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='sigmoid', input_dim = half))\n",
    "model.add(Dropout(0.25))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=16, verbose = 0)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NN Accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the regression model\n",
    "print(\"Mean absolute error =\", round(metrics.mean_absolute_error(y_test, y_predict), 2))\n",
    "print(\"Mean squared error =\", round(metrics.mean_squared_error(y_test, y_predict), 2)) \n",
    "rmse = metrics.mean_squared_error(y_test, y_predict)\n",
    "print(\"Root Mean squared error =\", round(sqrt(rmse),2))\n",
    "print(\"Median absolute error =\", round(metrics.median_absolute_error(y_test, y_predict), 2)) \n",
    "print(\"Explain variance score =\", round(metrics.explained_variance_score(y_test, y_predict), 2)) \n",
    "print(\"R2 score =\", round(metrics.r2_score(y_test, y_predict), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(x_test)\n",
    "y_predict = y_predict.reshape(len(y_predict))\n",
    "\n",
    "diff = y_test - y_predict\n",
    "plt.hist(diff,bins = 30, color = 'blue')\n",
    "plt.title('Prediction Errors')\n",
    "plt.xlabel('Phenotype prediction error')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "explainer = shap.DeepExplainer(model, x_train)\n",
    "shap_values = explainer.shap_values(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassoReg = linear_model.Lasso(alpha=.1)\n",
    "lassoReg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = lassoReg.coef_\n",
    "coeffs = abs(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = lassoReg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error = 0.36\n",
      "Mean squared error = 0.2\n",
      "Root Mean squared error = 0.45\n",
      "Median absolute error = 0.3\n",
      "Explain variance score = 0.5\n",
      "R2 score = 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean absolute error =\", round(metrics.mean_absolute_error(y_test, y_predict), 2))\n",
    "print(\"Mean squared error =\", round(metrics.mean_squared_error(y_test, y_predict), 2)) \n",
    "rmse = metrics.mean_squared_error(y_test, y_predict)\n",
    "print(\"Root Mean squared error =\", round(sqrt(rmse),2))\n",
    "print(\"Median absolute error =\", round(metrics.median_absolute_error(y_test, y_predict), 2)) \n",
    "print(\"Explain variance score =\", round(metrics.explained_variance_score(y_test, y_predict), 2)) \n",
    "print(\"R2 score =\", round(metrics.r2_score(y_test, y_predict), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
